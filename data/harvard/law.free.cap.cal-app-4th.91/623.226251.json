{
  "casebody": {
    "data": "<casebody firstpage=\"623\" lastpage=\"655\" xmlns=\"http://nrs.harvard.edu/urn-3:HLS.Libr.US_Case_Law.Schema.Case_Body:v1\">\n<docketnumber data-order=\"0\" data-type=\"docketnumber\" id=\"b599-4\">[No. F034208.</docketnumber>\n<court data-order=\"1\" data-type=\"court\" id=\"Asu\">Fifth Dist.</court>\n<decisiondate data-order=\"2\" data-type=\"decisiondate\" id=\"AZI\">Aug. 14, 2001.]</decisiondate>\n<parties data-order=\"3\" data-type=\"parties\" id=\"b599-5\">THE PEOPLE, Plaintiff and Respondent, v. FREDERICK RAY BROWN, Defendant and Appellant.</parties>\n<p data-order=\"4\" data-type=\"summary\" id=\"b599-6\">[Opinion certified for partial publication.<footnotemark>*</footnotemark>]</p>\n<p data-order=\"5\" data-type=\"attorneys\" id=\"b601-7\"><page-number citation-index=\"1\" label=\"625\">*625</page-number>Counsel</p>\n<p data-order=\"6\" data-type=\"attorneys\" id=\"b601-8\">David Joseph Macher, under appointment by the Court of Appeal, for Defendant and Appellant.</p>\n<p data-order=\"7\" data-type=\"attorneys\" id=\"b601-9\">Bill Lockyer, Attorney General, David P. Druliner, Chief Assistant Attorney General, Robert R. Anderson, Assistant Attorney General, W. Scott Thorpe and David A. Rhodes, Deputy Attorneys General, for Plaintiff and Respondent.</p>\n<footnote data-order=\"8\" data-type=\"footnote\" id=\"x999-1\" label=\"*\">\n<p id=\"b599-10\">Pursuant to California Rules of Court, rules 976(b) and 976.1, this opinion is certified for publication with the exception of part II.</p>\n</footnote>\n<opinion data-order=\"9\" data-type=\"opinion\" id=\"x999-2\" type=\"majority\">\n<p id=\"b602-3\"><page-number citation-index=\"1\" label=\"626\">*626</page-number>Opinion</p>\n<author id=\"b602-4\">DIBIASO, Acting P. J.</author>\n<p id=\"Aq3\">The jury found defendant and appellant Frederick Ray Brown guilty of forcible rape (Pen. Code, \u00a7 261, subd. (a)(2); count l)<footnotemark>1</footnotemark> and incest (\u00a7 285; count 2). The trial court found true the special allegations that Brown had suffered two prior serious felony convictions within the meaning of section 667, subdivision (a), and the \u201cThree Strikes\u201d law (\u00a7 1170.12), and had served five prior prison terms (\u00a7667.5, subd. (b)). Brown was sentenced to 38 years to life in prison.</p>\n<p id=\"b602-5\">We affirm the judgment. For no purpose other than to expand the universe of reported decisions that deal with DNA<footnotemark>2</footnotemark> evidence, we publish the portion of this opinion which addresses Brown\u2019s contention the trial court erred by admitting DNA evidence because (a) the database used to calculate the probability of his genetic profile was for various reasons inadequate, and (b) the prosecution failed to call one of the DNA analysts to testify as to her testing procedures.</p>\n<p id=\"b602-6\">Discussion</p>\n<p id=\"b602-7\">I.</p>\n<p id=\"b602-8\">Brown contends the trial court committed reversible error by admitting DNA evidence, which established he could not be excluded as a source of the perpetrator\u2019s DNA.<footnotemark>3</footnotemark>\n                   He raises his contentions under the third prong of <em>People v. Kelly </em>(1976) 17 Cal.3d 24 [130 Cal.Rptr. 144, 549 P.2d 1240], in which the Supreme Court articulated this three-step test for the admission of evidence generated by a new scientific technique: (1) the reliability of the technique must be sufficiently established to have gained general acceptance in the relevant scientific community; (2) the witness providing the evidence must be properly qualified as an expert; and (3) the evidence must establish that, in the particular case, the correct and accepted scientific technique was actually followed. <em>(People v. Kelly, supra, </em>17 Cal.3d at p. 30; <em>People </em>v. <em>Soto </em>(1999) 21 Cal.4th 512, 518-519 [88 Cal.Rptr.2d 34, 981 P.2d 958]; <em>People v. Venegas </em>(1998) 18 Cal.4th 47, 81 [74 Cal.Rptr.2d 262, 954 P.2d 525].)</p>\n<p id=\"b602-9\">Brown stipulated at trial to the scientific acceptance of the PCR (polymerase chain reaction) techniques used in this case, the first <em>Kelly </em><page-number citation-index=\"1\" label=\"627\">*627</page-number>prong,<footnotemark>4</footnotemark> and he has not challenged the finding that his DNA profile matched that of the perpetrator. However, he contends use of the Cellmark African-American database and calculations of genotypic frequencies derived from that database did not amount to correct and accepted procedure under Kelly\u2019s third prong. Specifically, he claims the database was inadequate because (1) it was not in Hardy-Weinberg equilibrium; (2) it was not in linkage equilibrium; (3) it was subject to population substructure because the samples were not randomly selected; and (4) it was too small. Brown also contends, again under the third <em>Kelly </em>prong, that the prosecution failed to establish that the DNA analysis itself was conducted in a proper and acceptable manner because only one of the two Cellmark DNA scientists who performed the analysis was called to testify, thereby precluding determination of whether the other analyst followed the proper procedures, and violating Brown\u2019s Sixth Amendment right to confront his accuser.</p>\n<p id=\"b603-5\">A. <em>DNA Evidence</em></p>\n<p id=\"b603-6\">1. <em>Genetic Profiling</em></p>\n<p id=\"b603-7\">We begin with some simplified biology. The genetics of a human cell can be compared to a library, the <em>genome, </em>composed of 46 \u201cbooks,\u201d each a single <em>chromosome. </em>The \u201ctext\u201d contained in the books is written in <em>DNA, </em>the chemical language of genetics. The \u201clibrary\u201d is compiled by the owner\u2019s parents, each of whom contributes 23 books, which are then matched up and arranged together in 23 paired sets inside the sacrosanct edifice of the <em>nucleus. </em>During embryonic development, the original library is copied millions of times so that each cell in the human body contains a copy of the entire library.<footnotemark>5</footnotemark></p>\n<p id=\"b603-8\">Twenty-two of the twenty-three paired sets of books are entitled \u201cChromosome 1\u201d through \u201cChromosome 22\u201d; externally, the two paired books of each set appear to be identical in size and shape. However, the 23d set, which contains information on gender, consists of one book entitled \u201cChromosome X\u201d (given by the mother) and one book entitled either \u201cChromosome X\u201d or \u201cChromosome Y\u201d (given by the father and determining the sex <page-number citation-index=\"1\" label=\"628\">*628</page-number>of the library\u2019s owner). The 22 sets comprising \u201cChromosome 1\u201d through \u201cChromosome 22\u201d address an enormous variety of topics describing the composition, appearance, and function of the owner\u2019s body. In addition, they include a considerable amount of what appears to be nonsense. The two paired books of each set, one book from each parent, address identical topics, but may contain slightly different information on those topics. Thus, two paired books opened to the same page contain corresponding \u201cparagraphs,\u201d but the text within those corresponding paragraphs may vary between the two books. For example, within the paragraph addressing eye color, one book may describe blue eyes while the other book of the set may describe brown eyes.<footnotemark>6</footnotemark></p>\n<p id=\"b604-4\">The two corresponding, but potentially variant, paragraphs in the two paired books are called <em>alleles. </em>If, for a particular topic (i.e., at a particular region or <em>locus </em>on the DNA), the allele from the mother is A and the corresponding allele from the father is B, the <em>genotype </em>at that locus is designated AB. The text of two corresponding alleles at any locus may be identical (a <em>homozygous </em>genotype, e.g., AA) or different (a <em>heterozygous </em>genotype, e.g., AB). Regardless, one person\u2019s genetic text is, in general, extremely similar to another person\u2019s; indeed, viewed in its vast entirety, the genetic text of one human library is 99.9 percent identical to all others. As a result, the text of most corresponding paragraphs varies only slightly among members of the population.</p>\n<p id=\"b604-5\">Certain alleles, however, have been found to contain highly variable text. For example, alleles are composed of highly variable text when they describe structures requiring enormous variability. Also, some alleles appear to contain gibberish that varies greatly, or repeated strings of text that vary not in text but in repeat number. These variants (polymorphisms) found at certain <em>loci </em>render each person\u2019s library unique<footnotemark>7</footnotemark> and provide forensic scientists a method of differentiating between libraries (people) through the use of forensic techniques that rely on the large number of variant alleles possible at each variable locus. For example, the combined libraries of the human population may contain two variant alleles at a particular locus, three at another, nine at another, and so on. Since each person receives two alleles for each locus, the number of possible combinations is further increased.</p>\n<p id=\"b604-6\">When a sample of DNA\u2014usually in the form of hair, blood, saliva, or semen\u2014is left at the crime scene by a perpetrator, a forensic genetic analysis <page-number citation-index=\"1\" label=\"629\">*629</page-number>is conducted. First, DNA analysts create a genetic \u201cprofile\u201d or \u201ctype\u201d of the perpetrator\u2019s DNA by determining which variants or alleles exist at several variable loci. Second, the defendant\u2019s DNA is analyzed in exactly the same manner to create a profile for comparison with the perpetrator\u2019s profile. If the defendant\u2019s DNA produces a different profile than the perpetrator\u2019s, even by only one allele, the defendant could not have been the source of the crime scene DNA, and he or she is absolutely exonerated.<footnotemark>8</footnotemark> If, on the other hand, the defendant\u2019s DNA produces exactly the same genetic profile, the defendant could have been the source of the perpetrator\u2019s DNA\u2014but so could any other person with the same genetic profile. Third, when the perpetrator\u2019s and the defendant\u2019s profiles are found to match, the statistical significance of the match must be explained in terms of the rarity or commonness of that profile within a particular population\u2014that is, the number of people within a population expected to possess that particular genetic profile, or, put another way, the probability that a randomly chosen person in that population possesses that particular genetic profile.<footnotemark>9</footnotemark> Only then can the jury weigh the value of the profile match. <em>(People v. Venegas, supra, </em>18 Cal.4th at p. 82.)<footnotemark>10</footnotemark></p>\n<p id=\"b605-5\">2. <em>Statistical Interpretation</em></p>\n<p id=\"b605-6\">Performing this last step\u2014the determination of the profile\u2019s rarity\u2014 requires information about the relevant population. For example, if the victim reports that the perpetrator had blue eyes and abnormally short fingers (brachydactyly), forensic scientists will need to know how rare the combination of blue eyes and brachydactyly is in the population. That determination requires knowledge of the <em>separate </em>frequencies of these two traits in the population\u2014how many people have blue eyes and how many people have brachydactyly. But it is impractical to actually examine the entire population to count every person with blue eyes and every person with brachydactyly; instead, scientists create a database of randomly selected people, and use the frequencies of the traits of that group of people to represent the entire population. If among the people used to compile the database the occurrence of blue eyes is fairly common and the occurrence of brachydactyly is very uncommon, then the probability of the two traits <page-number citation-index=\"1\" label=\"630\">*630</page-number>occurring <em>together </em>will be extremely rare. That determination, derived from the database, is presumed to apply to the entire population the database was created to represent. Therefore, the reasoning goes, if very few people are expected to have both traits\u2014that is, if the profile is rare\u2014the probability is greater that a defendant who possesses both traits is in fact the perpetrator.</p>\n<p id=\"b606-4\">In reality, forensically important alleles do not manifest themselves in obvious physical traits, but the idea is the same. Because allele frequencies cannot be determined from external appearances, preparation of a database requires collection of DNA samples (usually blood) from unrelated individuals in the relevant population, genetic analysis of each DNA sample to determine the alleles present at each locus tested, tally of the various alleles at each locus, and statistical analysis of the tallied results to determine the frequency of each allele (the allele frequency) and then the frequency of every possible corresponding set of two alleles (the genotype frequency) at each locus.<footnotemark>11</footnotemark> These database frequencies become standard values from which a perpetrator\u2019s profile can be given a numerical probability of existing in a population.<footnotemark>12</footnotemark></p>\n<p id=\"b606-5\">That numerical probability is generally calculated using the \u201cproduct rule,\u201d which posits that the probability of several things occurring together is the product of their separate probabilities. (See Kaye, <em>DNA Evidence: Probability, Population Genetics, and the Courts </em>(1993) 7 Harv. J.L. &amp; Tech. 101, 127-128.) For example, the probability of \u201cheads\u201d coming up on three successive coin tosses is the probability of heads on the first toss (1 in 2), multiplied by the probability of heads on the second toss (1 in 2), multiplied by the probability of heads on the third toss (1 in 2), resulting in an overall probability of 1 in 8.<footnotemark>13</footnotemark> Similarly, if a set of paired alleles (a genotype) is known to occur in 1 in 3.47 people and another set of paired alleles is known to occur in 1 in 18.52 people, then the probability of <em>both </em>sets occurring in the <em>same </em>person is 1/3.47 multiplied by 1/18.52, or 1 in 64.26 people. When more alleles are examined, the probability of a multilocus profile can be exceedingly rare, even one in hundreds of billions, and therefore the profile is highly distinctive.<footnotemark>14</footnotemark></p>\n<p id=\"b606-6\">Statistical evaluation raises two major issues with regard to uncertainty. One relates to substructure in the population. The other relates to the <page-number citation-index=\"1\" label=\"631\">*631</page-number>characteristics of the database, such as its size and whether it is representative of the relevant population. (NRCII, <em>supra, </em>at p. 125.)</p>\n<p id=\"b607-5\">a. <em>Hardy-Weinberg Equilibrium</em></p>\n<p id=\"b607-6\">The use of the product rule to calculate the overall probability of a genetic profile requires two conditions within the database population. The first condition is Hardy-Weinberg (HW) equilibrium, the state in which the alleles at a <em>single </em>locus are independent of each other. Thus, a population is in HW equilibrium if inheritance of one allele at a locus is unaffected by inheritance of another allele at the same locus.<footnotemark>15</footnotemark> Expected HW proportions result when the inheritance of alleles in a population is random rather than affected by pressures such as inbreeding, common ancestry, and small or isolated subpopulations.<footnotemark>16</footnotemark> (NRCII, <em>supra, </em>at p. 98; see also <em>People v. Soto, supra, </em>21 Cal.4th at pp. 525 -526.)</p>\n<p id=\"b607-7\">The HW expectations, however, are infrequently realized. Instead, populations are usually composed of subpopulations having allele probabilities that depart from equational equilibrium, a phenomenon known as population substructure. (Devlin &amp; Roeder, <em>DNA Profiling: Statistics and Population Genetics </em>in Modem Scientific Evidence: The Law and Science of Expert Testimony (1997) \u00a7 18-3.2.1 (hereafter Modem Scientific Evidence).) Several years ago, the problem of population substructure raised a controversy over whether the product mle, in its unmodified form, could be used to accurately calculate profile frequencies.  In response, the National Research Council (NRC)<footnotemark>17</footnotemark> published reports for guidance in the <page-number citation-index=\"1\" label=\"632\">*632</page-number>field of forensic DNA analysis. The first report (NRCI)<footnotemark>18</footnotemark> was issued in 1992, followed by a second report (NRCII)<footnotemark>19</footnotemark> in 1996, which reevaluated NRCI and concluded the dispute over the product rule had been resolved. NRCII acknowledged that when population substructure exists HW equilibrium is often disrupted and thus the application of standard HW presumptions to calculate genotype frequencies is inappropriate; indeed, it \u201cwill always lead to an underestimate of homozygous genotype frequencies and usually to an overestimate of heterozygote frequencies.\u201d (NRCII, <em>supra, </em>at p. 99.) NRCII therefore advised that calculations of genotype frequencies be adjusted or corrected when a database is affected by population substructure. NRCII\u2019s \u201capproach is not to assume HW proportions, but to use procedures that take deviations from HW into account.\u201d (NRCII, <em>supra, </em>at p. 104.)<footnotemark>20</footnotemark></p>\n<p id=\"b608-4\">Because heterozygote frequencies are overestimated by the HW equation, the defendant benefits from its use to calculate heterozygote frequencies. A correction is required, however, for calculation of homozygote frequencies, which are underestimated by the HW equation as being rarer than they actually are. Accordingly, for PCR-based DNA profiling, NRCII\u2019s Recommendation 4.1<footnotemark>21</footnotemark> advises the following procedure to compensate for deviations caused by population substructure:</p>\n<p id=\"b609-4\"><page-number citation-index=\"1\" label=\"633\">*633</page-number>For heterozygous genotypes:</p>\n<p id=\"b609-5\">Use the standard HW proportion of 2pq to calculate a heterozygous genotype frequency because the result is a conservative overestimate of the probability of the genotype, which functions in the defendant\u2019s favor.</p>\n<p id=\"b609-6\">For homozygous genotypes:</p>\n<p id=\"b609-7\">Instead of using the standard HW proportion of p2 to calculate a homozygous genotype frequency, use p2 + p(l - p)0, where 0 (theta) is between 0.01 (a conservative value appropriate for most United States subpopulations) and 0.03 (a more conservative value appropriate for small, isolated subpopulations), to correct for the underestimate caused by substructure. The 9 value of 0.03 may generally be chosen to ensure a conservative calculation biased toward the defendant. (NRCII, <em>supra, </em>at p. 122.)</p>\n<p id=\"b609-8\">b. <em>Linkage Equilibrium</em></p>\n<p id=\"b609-9\">The second condition required for use of the product rule is linkage equilibrium\u2014independence among <em>many </em>loci or, more precisely, between many sets of two loci. Linkage equilibrium exists when inheritance of alleles at one locus is not affected by inheritance of alleles at another locus, such that the various single-locus genotypes at each locus are statistically independent. A lack of linkage equilibrium usually arises due to factors such as inbreeding and physical proximity of loci on the DNA (increasing the chance they could be inherited together), although disequilibrium does not require that the loci be on the same chromosome. (See Modem Scientific Evidence, <em>supra, </em>at p. 701; NRCII, <em>supra, </em>at p. 106.) An example of linkage disequilibrium is found in Nordic populations where blond hair, blue eyes, and fair skin are not inherited independently of each other, but are found together in a disproportionate number of people. Theoretically, only when the population is in linkage equilibrium (in regard to the relevant loci) may the single-locus genotype frequencies of several loci properly be multiplied together by the product mle to give a legitimate and reliable overall profile frequency. (Modem Scientific Evidence, <em>supra, </em>at p. 722; see also <em>People v. Soto, supra, </em>21 Cal.4th at pp. 525 -526.)</p>\n<p id=\"b609-10\">NRCII, however, explains that the effects of small departures from linkage equilibrium are usually inconsequential, especially when the genotype at <page-number citation-index=\"1\" label=\"634\">*634</page-number>each locus is assigned a conservative value. \u201c[W]hereas a population broken into subgroups [causing a departure from HW equilibrium] has a systematic bias in favor of homozygosity, departures from [linkage equilibrium] increase some associations and decrease others in about equal degrees. Although there might be linkage disequilibrium, we would expect some canceling of opposite effects. The important point, however, is not the canceling but the small amount of linkage disequilibrium .... In this case, multiplying together the frequencies at the several loci will yield roughly the correct answer. An estimated frequency of a composite genotype based on the product of <em>conservative estimates </em>at the several loci is expected to be conservative for the multilocus genotypes.\u201d (NRCII, <em>supra, </em>at p. 107, italics added, fn. omitted.)</p>\n<p id=\"b610-4\">Thus, although substantial linkage disequilibrium presents a significant problem, typically only small departures actually occur.</p>\n<p id=\"b610-5\">c. <em>Random Sampling</em></p>\n<p id=\"b610-6\">Ideally, a database would be composed of samples chosen entirely at random so the relevant population would be properly represented. Yet, it is \u201cdifficult, expensive, and impractical to arrange a statistically valid random-sampling scheme.\u201d (NRCII, <em>supra, </em>at p. 126.) But \u201c[t]he saving point is that the [alleles] in which we are interested are believed theoretically and found empirically to be essentially <em>uncorrelated </em>with the means by which samples are chosen. Comparison of estimated profile frequencies from different data sets shows relative insensitivity to the source of the data . . . .\u201d <em>(Ibid., </em>italics added.) \u201cConvenience samples,\u201d taken from people who contribute to blood banks or who have been involved in paternity suits, are appropriate for forensic use for two reasons. \u201cFirst, the loci generally used for identification are usually not parts of functional genes and therefore are unlikely to be correlated with any behavioral or physical traits that might be associated with different subsets of the population. Second, empirical tests have shown only very minor differences among the frequencies of DNA markers from different subpopulations or geographical areas.\u201d <em>(Id. </em>at pp. 30, 149-156.) \u201cWithin a racial group, geographic origin and ethnic composition have very little effect on the frequencies of forensic DNA profiles, although there are larger differences between major groups (races).\u201d <em>(Id. </em>at p. 156.)<footnotemark>22</footnotemark> If the sampling method nevertheless produces substructuring, those effects can be corrected by use of more conservative frequencies calculated using Recommendation 4.1. <em>(Id. </em>at p. 29.)</p>\n<p id=\"b611-4\"><page-number citation-index=\"1\" label=\"635\">*635</page-number>d. <em>Database Size</em></p>\n<p id=\"b611-5\">A database is composed of a relatively small number of samples and is expected to substitute for a population, and thus there is a nagging question of the minimum database size required to adequately represent that population. Obviously, the larger the database, the more definitive the population data,<footnotemark>23</footnotemark> but time and expense limit what is practical. Unfortunately, there is no simple answer to the question of adequate database size, and experts promote widely differing standards. Experts agree \u201cthe question of database size should be considered. Larger samples give more precise estimates of. allele frequencies than smaller ones, <em>but there is no sharp line for determining when a database is too small.\u201d </em>(Kaye &amp; Sensabaugh (2000) <em>Reference Guide on DNA Evidence </em>in Reference Manual on Scientific Evidence (2d ed.) p. 557, fn. omitted, italics added <em>(Reference Guide on DNA Evidence)', </em>see also Modem Scientific Evidence (2000 supp.) pp. 260-261.) Furthermore, many of the earlier suggestions on database size were based on earlier methods and thus may or may not be as applicable to PCR-based testing.</p>\n<p id=\"b611-6\">One commentator summed up the situation, as of 1998, in this way: \u201cPublished populations for STR [short tandem repeat] loci [for use in a PCR-based test] are generally of the order of either 100 or 200, but sometimes smaller numbers are reported for sub-populations. The International Society of Forensic Haemogenetics has recommended that 100 persons are sufficient[<footnotemark>24</footnotemark>], but no basis for this size is given and the number may well be a carry-over from what was considered adequate[<footnotemark>25</footnotemark>] for polymorphic protein systems. The Committee on DNA Technology in Forensic Science, when originally reporting the ceiling principle [i.e., NRCI], also suggested databases of 100.[<footnotemark>26</footnotemark>] More recently, though, in describing databases generally the Committee suggests at least a few (or several) hundred persons.[<footnotemark>27</footnotemark>] Several authors (Lander[<footnotemark>28</footnotemark>] and Devlin et al.,[<footnotemark>29</footnotemark>, <footnotemark>30</footnotemark>] for example) have, however, argued that a sample of 100 individuals is too small. Lander, moreover, has suggested that even a database of 500 is too small although he has now given <page-number citation-index=\"1\" label=\"636\">*636</page-number>qualified support[<footnotemark>31</footnotemark>] for a database of 100 individuals. Weir [<footnotemark>32</footnotemark>] also has implied that samples of 100 individuals are too small because tests for independence of allele frequencies will have low power. Nevertheless, some practical support for a sample size of 100 was shown by Pacek et al.[<footnotemark>33</footnotemark>] in a study which compared allele frequencies obtained from individuals to allele frequencies of pooled blood samples.\u201d (Harding &amp; Swanson, <em>DNA Database Size </em>(1998) 43 J. Forensic Sci. 24S-249.)<footnotemark>34</footnotemark></p>\n<p id=\"b612-4\">As Harding and Swanson\u2019s comment recognizes, the question of minimum database size has been unsettled among scientists and statisticians for many years and shows no sign of imminent or easy resolution. Even NRC has been unable to decide on an advisable minimum database size\u2014NRCI advised a minimum of 100 persons (NRCI, <em>supra, </em>at pp. 74-96), whereas NRCII advised a minimum of at least a few or several hundred persons (NRCII, <em>supra, </em>at pp. 34, 112, 114, 156).<footnotemark>35</footnotemark> But NRCII also acknowledged that fewer data were available (in 1996) for PCR-based testing and therefore those databases might be smaller than those typically used for RFLP-based <page-number citation-index=\"1\" label=\"637\">*637</page-number>testing. (NRCII, <em>supra, </em>at p. 117 [\u201cThe databases are smaller, but the studies that have been done show the same agreement with HW and LE that [RFLP-based] VNTRs do [citations].\u201d].) To account for the less extensive and less varied data, NRCII advised use of a correction factor more favorable to the defendant (9 = 0.03) in the application of Recommendation 4.1. (NRCII, <em>supra, </em>at pp. 119, 122.)</p>\n<p id=\"b613-5\">Without definitive guidelines from the scientific community, the courts have approved the use of databases of various sizes. For example, the court in <em>Commonwealth </em>v. <em>Rosier </em>(1997) 425 Mass. 807 [685 N.E.2d 739], confronted with contentions similar to those raised in the present case, found Cellmark\u2019s 100-person database adequate for PCR-based testing. The court stated: \u201cThe defendant argues that Cellmark\u2019s database is too small and, for various other reasons, unreliable. fl[] The judge acted properly in rejecting the defendant\u2019s arguments. He accepted the expert testimony that the Cell-mark database was adequate and common within the field and that a database larger than Cellmark\u2019s would produce \u2018no significant difference in the result.\u2019 There was expert and scientific evidence that the Cellmark database met two factors critical to the reliability of a database. The first factor, \u2018linkage equilibrium\u2019 (LE), establishes that the various chromosomal loci identified in a database occur randomly in proportion to one another, thus assuring that results related to one locus are not affected by, nor predictive of, the results related to another. The second factor is \u2018Hardy-Weinberg equilibrium\u2019 (HW). A database is considered to be \u2018in HW\u2019 when the predicted values for the various loci within the database actually correspond to those found in the population, assuming mates are randomly chosen. Thus, it was properly found that the Cellmark database was both in LE and in HW. The database and statistical results reached by Cellmark were also independently verified by Dr. Basten through calculations of \u2018confidence intervals\u2019 and a comparison of Cellmark\u2019s results with other databases that achieved statistically comparable results. Dr. Basten also concluded that the methods used by Cellmark to generate statistical results are \u2018generally accepted\u2019 within the field of population genetics, and that the statistical results they produce are reliable and accurate.\u201d <em>(Commonwealth v. Rosier, supra, </em>685 N.E.2d at pp. 743-744 [DQA1, polymarker, and STR loci tested], fns. omitted.)</p>\n<p id=\"b613-6\">B. <em>Expert Testimony and Evidence</em></p>\n<p id=\"b613-7\">In this case, nine variable loci were tested to create the genetic profiles of the perpetrator, Brown, and the victim. For each profile, six DNA regions or <page-number citation-index=\"1\" label=\"638\">*638</page-number>loci were tested for the \u201cpolymarker\u201d and \u201cDQA1\u201d<footnotemark>36</footnotemark> alleles and three loci were tested for \u201cshort tandem repeat\u201d (STR) alleles. All nine of the tests utilized PCR methodology, which the defense stipulated was accepted by the scientific community. Expert testimony established that Brown\u2019s profile matched the perpetrator\u2019s.</p>\n<p id=\"b614-4\">The match was interpreted by using Cellmark\u2019s databases to assign a frequency to each of the nine genotypes in the profile, then multiplying those genotypes together to yield the following probabilities of finding the profile in various populations: 1 in 580 billion Caucasian individuals, 1 in 180 million African-American individuals, and 1 in 140 billion Hispanic individuals.</p>\n<p id=\"b614-5\">1. <em>Bruce Weir</em></p>\n<p id=\"b614-6\">Dr. Bruce Weir, a population geneticist, evaluated the data generated by Cellmark\u2019s databases. He calculated the frequencies for each of the alleles and genotypes for the three databases, and his results were published in a report. Weir\u2019s report was admitted into evidence, but Weir did not testify. In his report evaluating Cellmark\u2019s databases, Weir cited NCRII, noting its recommendation that \u201cattention on formal testing for independence of alleles within and between loci no longer be emphasized. Instead acknowledgement is to be given to the possibility of departures from Hardy-Weinberg equilibrium at single loci, and recognition is to be given to the fact that any dependencies among loci would be small.\u201d Weir then stated: \u201cRecommendation 4.1 is that heterozygote frequencies should be calculated as the product of allele frequencies but that homozygote frequencies should be modified to allow for inbreeding of an extent 9 = 0.03 (Equation 4.4a).\u201d<footnotemark>37</footnotemark> Weir acknowledged the databases contained \u201coccasional . . . departures from independence.\u201d He explained further, in the portion of the report entitled \u201cOne-locus Testing,\u201d that \u201c[flor all loci, except GC in the Caucasian database and LDLR in the African American database, there was no evidence for a departure from Hardy-Weinberg equilibrium . . . .\u201d<footnotemark>38</footnotemark></p>\n<p id=\"b614-7\">2. <em>Kathryn Colombo</em></p>\n<p id=\"b614-8\">At the <em>Kelly </em>hearing, Kathryn Colombo, a staff DNA analyst at Cellmark, testified that she and Lisa Grossweiller, another Cellmark DNA analyst, <page-number citation-index=\"1\" label=\"639\">*639</page-number>performed the PCR testing of Brown\u2019s DNA to determine Brown\u2019s genotypes at nine loci. Grossweiller first analyzed the DQ alpha locus and five other loci known collectively as the polymarker loci. Colombo then tested STR at three more loci.</p>\n<p id=\"b615-5\">Colombo explained her own testing, as well as Grossweiller\u2019s. Colombo reviewed the case file, the protocols used by Grossweiller, and Grossweiller\u2019s test results. The laboratory report authored by Grossweiller containing the results of her testing was a record kept by Cellmark in the regular course of business. Colombo reviewed Grossweiller\u2019s report and results, and determined that Grossweiller had followed proper scientific procedures that were accepted by the scientific community for the performance of the PCR-based DQ alpha and polymarker tests.</p>\n<p id=\"b615-6\">Colombo explained the three Cellmark databases contained samples from 100 Caucasians, 100 African-Americans, and 200 Hispanics.<footnotemark>39</footnotemark> Cellmark then analyzed the DNA from each individual database and sent the raw data to Weir, a population geneticist. Weir evaluated the appropriateness of the databases and calculated the frequency for each genotype; those data were then tabulated for use by Cellmark analysts. Colombo stated that when she performed the DNA analysis, she transcribed the frequencies calculated by Weir for each locus she tested, then multiplied the frequencies together (using the product rule) to reach an overall probability. She stated use of the product rule with respect to PCR profiling is accepted throughout the scientific community. Colombo described the report (in evidence) in which she listed Brown\u2019s genotype frequencies of the nine tested loci, assigned each the value calculated by Weir from the database, then multiplied the frequencies together to obtain the overall profile frequency. Her work on that report had been reviewed and initialed by a staff Ph.D. Also, Colombo stated Cellmark adopted the use of NRCH\u2019s Recommendation 4.1 to \u201censure[] that [the] database does not artificially overestimate the rareness of a particular type.\u201d</p>\n<p id=\"b615-7\">Colombo testified Brown\u2019s genetic profile was one which \u201cyou would expect to see ... in approximately 1 in 580 billion\u201d Caucasian individuals, \u201cfor African-Americans, the frequency is 1 in 180 million; and for the Hispanic population, 1 in 140 billion.\u201d</p>\n<p id=\"b615-8\">On cross-examination, Colombo explained the 100 African-American samples in the database were collected from Cellmark\u2019s paternity casework. Blood was drawn from mothers and alleged fathers, but not children. Colombo stated some substructuring occurs within ethnic groups and therefore the NRCII Recommendation 4.1 correction factor is used. She explained <page-number citation-index=\"1\" label=\"640\">*640</page-number>that a database of 100 individuals can be used to generalize an entire population of millions because \u201cwith these PCR tests we are dealing with a limited number of possible [geno]types. At five of the six regions that were done in the first part of the testing, you can only be either two or three types. The most types possible are nine in one of the STR regions.</p>\n<blockquote id=\"b616-4\">\u201cSo when you look at 100 individuals, you have to remember that since an individual inherits half their DNA from their mother and half from the father, that we actually have 200 pieces of information. And 200 pieces of information, seeing how those particular types fall out, 50 individuals in a database is considered a minimum but adequate to do this, because you are dealing with a limited number of individuals. So once you have determined the proportion of a particular type, it would be approximately the same if you looked at 100 individuals, a thousand, 10,000.\u201d</blockquote>\n<p id=\"b616-5\">Colombo agreed that 9 of the 100 samples in the database were taken from people in Baton Rouge and that other cities also seemed to be represented in large proportion, but she testified there was no danger that certain subgroups would have a disproportionate effect on the database because the \u201ccharacteristics are considered to be inherited randomly. And that means that someone in Baton Rouge that is a Type A at one of the [loci] doesn\u2019t know that he\u2019s a Type A and he wouldn\u2019t say, gee, I need to marry someone who is Type A so our children can all be Type A so therefore you have some substructuring in that population. They are generally to be considered randomly inherited although there is some substructuring, and that\u2019s why the correction factor has been used.\u201d Defense counsel asked why, if the types are inherited randomly, would the value be 1 in 180 million for African-Americans, but 1 in 580 billion for Caucasians. Colombo answered that the NRCII report \u201cdoes recognize that there are departures from randomness. And one of the models that Dr. Weir applied to our data was the Hardy-Weinberg model, and he states that in his report. And it\u2019s really\u2014it\u2019s the entire reason for using the correction factor. And we actually use the more conservative value. [The NRCII report] suggests] two, and we use the most conservative.\u201d Again later, defense counsel asked if there are certain genetic profiles that are more common to people of different races. Colombo explained: \u201cRight. It is recognized that there is substructuring within ethnic groups, and that\u2019s why an empirically derived correction factor is used. ft[] . . . [ft| That is a value that was derived empirically from actual population studies where the departure from randomness is determined, and it\u2019s a value that\u2019s used to ensure that a particular type is not made too rare in your database. So to make the value more conservative.\u201d She continued: \u201cSo it has been theorized that substructuring would result in an overabundance of homozygous types. And as a result of population studies, they have found <page-number citation-index=\"1\" label=\"641\">*641</page-number>this to actually be trae. HQ So it\u2019s my understanding that the correction factor somehow mediates so that you are not artificially overestimating the rareness of homozygous types in your database. And the correction factor actually is only used when calculating genotype frequencies of homozygotes. HO \u2022 \u2022 \u2022 HD It corrects for substructuring in your database.\u201d</p>\n<p id=\"b617-5\">On redirect, Colombo explained the meaning of the probability of 1 in 180 million, as follows: \u201cThat figure gives us an idea of how rare or how common a particular profile is. So it\u2019s not really a chance thing. Either it is his DNA so it\u2019s 100 percent or it\u2019s not, which is zero percent. So the number helps us to infer the rareness or the commonness of a particular type. And, of course, as a profile becomes increasingly rare, the inference is stronger that that individual is actually the source of the DNA.\u201d</p>\n<p id=\"b617-6\">Colombo opined that Brown could not be excluded as the source of the perpetrator\u2019s DNA and that the frequency with which all nine loci would match this profile was \u201cone person in 180 million out of an African-American population.\u201d</p>\n<p id=\"b617-7\">3. <em>Thomas Fedor</em></p>\n<p id=\"b617-8\">Thomas Fedor, a forensic serologist, worked for Serological Research Institute, which was entirely unrelated to Cellmark. Fedor reviewed the Cellmark laboratory report of Brown\u2019s DNA analysis and various other documents, including Weir\u2019s report. He also had the opportunity to discuss with Colombo the testing she had conducted in this case. Fedor verified that the product rale was properly applied in Cellmark\u2019s report of Brown\u2019s DNA analysis.</p>\n<p id=\"b617-9\">Fedor explained that the product rale calculates \u201cthe overall prevalence of these combination markers in the population at large.\u201d With respect to Cellmark\u2019s analysis of Brown\u2019s DNA, Fedor stated: \u201cThe final Product Rule calculation for all the markers tells us that these markers are found together or expected to be found together in approximately 1 in 580 billion Caucasians, 1 in 180 million African Americans, and 1 in 140 billion Hispanics. HI] Obviously, there aren\u2019t that many Caucasians and there aren\u2019t that many Hispanics. So another way that one might look at this is what is the chance that\u2014if we select a Caucasian individual at random ... or off the street, what is the chance he would have genetic markers the same as all nine of these? And the chance is approximately 1 in 580 billion, and we can think of that as extremely remote.\u201d Fedor said use of the product rale is \u201cperfectly safe\u201d in DNA profiling, but the \u201ckey has been really judging whether those <page-number citation-index=\"1\" label=\"642\">*642</page-number>markers are independent.\u201d The following colloquy occurred: \u201c[Fedor:] The assumption of independence on which the [Product] Rule calculation is based is a concept that\u2019s taken from theoretical genetics. . . . [W]e have family groupings in real world populations, and the effect of family grouping is . . . substructure in the population. That has the effect that there are small deviations from independence in these markers in real world populations.</p>\n<p id=\"b618-4\">\u201cAfter a good deal of study, it has been found possible to take the substructure into account by means of a statistical treatment. That particular statistical treatment involves a calculation including a coancestry coefficient.[<footnotemark>40</footnotemark>] And, indeed, that coancestry coefficient is what has been applied by the Cellmark Lab to their population data so that these markers can be treated as though they are effectively independent once the coancestry coefficient is included in the calculations.</p>\n<p id=\"b618-5\">\u201c[Prosecutor:] So this additional figuring in is what makes the Product Rule\u2019s application in this particular case or any case using these markers is what makes it reliable?</p>\n<p id=\"b618-6\">\u201c[Fedor:] Yes, ma\u2019am, that\u2019s exactly correct.</p>\n<p id=\"b618-7\">\u201c[Prosecutor:] Where does that corrective measure or statistical additional input come from?</p>\n<p id=\"b618-8\">\u201c[Fedor:] Well, it comes from genetic\u2014statistical genetic theory, which is a complex body ... of which I have only a passing familiarity, but I believe the Court is aware of the document that was prepared for Cellmark Diagnostics by Professor Bruce Weir, [ft] \u2022 \u2022 \u2022 [1D \u2022 \u2022 \u2022 In this document, Professor Weir, who is perhaps one of the world\u2019s leading authorities in the field of statistical genetics, has examined the population survey data that Cellmark Lab has collected and has actually applied the statistical correction involving the coancestry coefficient to that data to provide figures for what we call in shorthand NRC 4.1 data.</p>\n<p id=\"b618-9\">\u201cNow, NRC 4.1 is a particular recommendation by the National Research Council in its evaluation of the forensic uses of DNA testing which provides that these coancestry coefficients be taken into account when calculating data for PCR testing, [ft] . . . [ft]</p>\n<p id=\"b618-10\">\u201c[Prosecutor:] And did you have an opportunity to review [the documents] to, in fact, determine if Cellmark Diagnostics in their analysis in this <page-number citation-index=\"1\" label=\"643\">*643</page-number>case in arriving at the frequency number . . . whether they, in fact, used that recommendation, that corrected factor?</p>\n<p id=\"b619-5\">\u201c[Fedor:] Yes. They have adopted Professor Weir\u2019s treatment of their data wholeheartedly.</p>\n<p id=\"b619-6\">\u201c[Prosecutor:] And, in fact, that corrective measure actually favors a suspect?</p>\n<p id=\"b619-7\">\u201c[Fedor:] <em>What it does is it corrects a tendency that small databases have ... to underestimate the frequency of something that is rare. </em>ft[] Let me say it a different way. If something is in the population to the extent of, say, two in a thousand, it\u2019s fairly rare. If you sample only a hundred members of that group, you may not find any instances of this thing that occurs only two in a thousand. And your sample of a hundred may say, well, this doesn\u2019t occur at all. We couldn\u2019t find it in a sample of a hundred. Well, that\u2019s an underestimate of its true frequency of two in a thousand, and it arrives because the sample is small.</p>\n<p id=\"b619-8\">\u201cIf you were to sample 10,000 of these things, you would have found about 20 of them. So what happens when your databases are small is that you tend to underestimate rare events, and <em>the calculation that NRC recommends be done corrects for . . . the potentially small size of a sample as well as the family grouping or the coancestry that may exist in the population.</em></p>\n<p id=\"b619-9\">\u201c[Prosecutor:] And that was done in this particular case?</p>\n<p id=\"b619-10\">\u201c[Fedor:] And that was done in this case, yes. [^] . . . [U]</p>\n<p id=\"b619-11\">\u201c[Prosecutor:] And in your review in this case, did, in fact, Cellmark apply the corrective measure that is recommended by the National Research Council in arriving at the figures that you\u2019ve just recited to us?</p>\n<p id=\"b619-12\">\u201c[Fedor:] Yes, indeed.\u201d (Italics added.)</p>\n<p id=\"b619-13\">On cross-examination, Fedor stated he used in his work a database consisting of about a thousand people in each ethnic group. He stated Cellmark\u2019s database was small, but some authorities believe databases of Cellmark\u2019s size are adequate. Furthermore, use of the correction factor compensated for any problems arising from inadequate size. Fedor provided the following testimony:</p>\n<blockquote id=\"b619-14\">\u201c[Defense Counsel:] You mentioned small databases. Do you consider a database of a hundred individuals to be small?</blockquote>\n<blockquote id=\"b620-3\"><page-number citation-index=\"1\" label=\"644\">*644</page-number>\u201c[Fedor:] It is small. I have read authorities who publish in the scientific literature who say that even such a small database can be adequate.</blockquote>\n<blockquote id=\"b620-4\">\u201c[Defense Counsel:] Is there some controversy on that point?</blockquote>\n<blockquote id=\"b620-5\">\u201c[Fedor:] There may be different schools of thought about that point, <em>but our concerns are alleviated by a particular statistical treatment. </em>In fact, that was used by Professor Weir. And that treatment is this. As I said, our concern about a small database is that it may tend to underestimate rare events. The correction that\u2019s commonly used [for] small databases is simply to add the observation in this case that you may never have seen before, add it to the database, that is, increase the database by one and add a new event to it. And what that does is it corrects for the opportunity that was missed in the original database to find this rare event. We have now found it by increasing the database by one.\u201d (Italics added.)</blockquote>\n<p id=\"b620-6\">On the topic of population substructure, the following was elicited:</p>\n<blockquote id=\"b620-7\">\u201c[Defense Counsel:] And you get radically different results just in multiplying out the Product Rule, say, as you did in this case between the subgroup of African-Americans and the subgroup of Caucasians?</blockquote>\n<blockquote id=\"b620-8\">\u201c[Fedor:] Yes. In this case, there are pronounced differences from several hundred billion in the case of Caucasians to 180 million in the case of African-Americans. That\u2019s quite a pronounced difference. There is a particular marker in this case that contributes a great deal to that pronounced difference. ft[] . . . [f]</blockquote>\n<blockquote id=\"b620-9\">\u201c[Defense Counsel:] And would it be fair to say that one of the dangers of a small database is not only that it might understate differences, but if a substructure or a subgroup is overrepresented in that particular small database, it will skew the results?</blockquote>\n<blockquote id=\"b620-10\">\u201c[Fedor:] That can happen, yes. If the small database has an inordinate number of members from a particular subpopulation, in theory you could overestimate the frequency of a marker in the population at large. That certainly can happen, yes. [H] . . . [H]</blockquote>\n<blockquote id=\"b620-11\">\u201c[Defense Counsel:] . . . [S]ay, in that 100 African-Americans you find out that nine, ten, or eleven of them came from, say, Louisiana. Just from what we know generally about the country, that would seem that that particular area is overrepresented in their population study.</blockquote>\n<blockquote id=\"b620-12\">\u201c[Fedor:] If Louisiana represents ten percent of the sample, then perhaps other states have been slighted, sir, yes.</blockquote>\n<blockquote id=\"b621-4\"><page-number citation-index=\"1\" label=\"645\">*645</page-number>\u201c[Defense Counsel:] Let us assume just hypothetically that the city of Baton Rouge, Louisiana, represents nine percent of the sample. Would this tend to make you believe that other areas have been slighted? ffl] . . . [H]</blockquote>\n<blockquote id=\"b621-5\">\u201cThe Court: Well, slighted in the sense that it would skew the reliability of the database; is that your question?</blockquote>\n<blockquote id=\"b621-6\">\u201c[Defense Counsel]: Yes, your Honor.</blockquote>\n<blockquote id=\"b621-7\">\u201cThe Court: Did you understand the question?</blockquote>\n<blockquote id=\"b621-8\">\u201c[Fedor:] I think I did, your Honor. What I would suggest is that initially we might have some concern as to whether African-Americans in Baton Rouge happen to constitute a close family grouping. Perhaps because for generations African-Americans have not left Baton Rouge or other African-Americans have not come in to Baton Rouge from elsewhere in the country. That would suggest a common ancestral heritage for African-Americans in Baton Rouge.</blockquote>\n<blockquote id=\"b621-9\">\u201c[Defense Counsel:] Now you mentioned small deviations in the statistical frequencies due to\u2014can be due to substructures of a particular population; is that right?</blockquote>\n<blockquote id=\"b621-10\">\u201c[Fedor:] Yes, sir.\u201d</blockquote>\n<p id=\"b621-11\">After hearing argument, the court ruled on the admissibility of the DNA evidence. The court stated:</p>\n<blockquote id=\"b621-12\">\u201cThe Court has considered all of the evidence, both oral and documentary, and recognizing that we do have some stipulations that ehminate some potential issues, specifically the stipulation that PCR is generally accepted as a reliable form of testing in the scientific community . . . , I have considered the three prongs of the Kelly case, and I am satisfied even assuming that the reliability of the scientific technique having gained general acceptance in the particular field to which it belongs, assuming that that must be established by the independent expert in this case, who would be Mr. Fedor, I do find that the first prong has been satisfied with the evidence presented. Certainly it\u2019s up to the jury to decide what weight to give to that. Actually, I guess it\u2019s a close decision. Right now it\u2019s the Court\u2019s decision to find that the first prong has been met.</blockquote>\n<blockquote id=\"b621-13\">\u201cThe second prong, as far as the witnesses being properly qualified as experts, I find it has been met. / <em>additionally find the third prong has been </em><page-number citation-index=\"1\" label=\"646\">*646</page-number><em>satisfied for purposes of this 402 hearing, that the correct scientific procedures were used in the particular </em>case, and that\u2019s the prong that the Court expects will be perhaps the main issue to the jury as to whether the jury decides that the scientific procedures being used were such that the jury should give this evidence more weight or less weight. At any rate, the motion is granted to admit the DNA evidence.\u201d (Italics added.)</blockquote>\n<p id=\"b622-4\">C. <em>Kelly\u2019s Third Prong</em></p>\n<p id=\"b622-5\">In <em>People </em>v. <em>Venegas, supra, </em>18 Cal.4th 47, the Supreme Court comprehensively explained the purpose of <em>Kelly\u2019s </em>third prong:</p>\n<blockquote id=\"b622-6\">\u201cThe <em>third prong </em>of the test was separately set forth in <em>Kelly </em>as follows: \u2018Additionally, the proponent of the evidence must demonstrate that correct scientific procedures were used in the particular case. . . .\u2019 [Citation.] [f] The <em>Kelly </em>test\u2019s third prong does not apply the Frye[<footnotemark>41</footnotemark>] requirement of general scientific acceptance\u2014it assumes the methodology and technique in question has already met that requirement. Instead, it inquires into the matter of whether <em>the procedures actually utilized in the case </em>were in compliance with that methodology and technique, as generally accepted by the scientific community. [Citation.] The third-prong inquiry is thus case specific; \u2018it cannot be satisfied by relying on a published appellate decision.\u2019 [Citation.] fl[] . . . \u2018Due to the complexity of the DNA multisystem identification tests and the powerful impact that this evidence may have on a jury, satisfying <em>Frye </em>[i.e., satisfying <em>Kelly\u2019s </em>first prong] alone is insufficient to place this type of evidence before a jury without a preliminary critical examination of the actual testing procedures performed. . . .\u2019 [Citation.] [H] . . . fl{]</blockquote>\n<blockquote id=\"b622-7\">\u201c. . . The <em>Kelly </em>test is intended to forestall the jury\u2019s uncritical acceptance of scientific evidence or technology that is so foreign to everyday experience as to be unusually difficult for laypersons to evaluate. [Citation.] In most other instances, the jurors are permitted to rely on their own common sense and good judgment in evaluating the weight of the evidence presented to them. [Citations.] [^] DNA evidence is different. Unlike fingerprint, shoe track, bite mark, or ballistic comparisons, which jurors essentially can see for themselves, questions concerning whether a laboratory has adopted correct, scientifically accepted procedures for [DNA testing] or determining a [profile] match depend almost entirely on the technical interpretations of experts. [Citation.] Consideration and affirmative resolution of those questions constitutes a <em>prerequisite to admissibility </em>under the third prong of <em>Kelly.</em></blockquote>\n<blockquote id=\"b622-8\">\u201cThe <em>Kelly </em>test\u2019s third prong does not, of course, cover all derelictions in following the prescribed scientific procedures. Shortcomings such as mislabeling, mixing the wrong ingredients, or failing to follow routine precautions <page-number citation-index=\"1\" label=\"647\">*647</page-number>against contamination may well be amenable to evaluation by jurors without the assistance of expert testimony. Such readily apparent missteps involve \u2018the degree of professionalism\u2019 with which otherwise scientifically accepted methodologies are applied in a given case, and so amount only to \u2018[cjareless testing affect[ing] the weight of the evidence and not its admissibility\u2019 [citations].</blockquote>\n<blockquote id=\"b623-5\">\u201cThe <em>Kelly </em>third-prong inquiry involves further scrutiny of a methodology or technique that has already passed muster under the central first prong of the <em>Kelly </em>test, in that general acceptance of its validity by the relevant scientific community has been established. The issue of the inquiry is whether the procedures utilized in the case at hand complied with that technique. Proof of that compliance does not necessitate expert testimony anew from a member of the relevant scientific community directed at evaluating the technique\u2019s validity or acceptance in that community. It does, however, require that the testifying expert understand the technique and its underlying theory, and be thoroughly familiar with the procedures that were in fact used in the case at bar to implement the technique. [Citations.]\u201d <em>(People v. Venegas, supra, </em>18 Cal.4th at pp. 78-81, italics in 2d quoted par. added.)</blockquote>\n<blockquote id=\"b623-6\">\u201cUnlike the independent appellate review of a determination of general scientific acceptance under <em>Kelly\u2019s </em>first prong, review of a third-prong determination on the use of correct scientific procedures in the particular case requires deference to the determinations of the trial court. [Citation.]\u201d <em>(People v. Venegas, supra, </em>18 Cal.4th at p. 91.)</blockquote>\n<p id=\"b623-7\">The third-prong hearing \u201cwill not approach the \u2018complexity of a full-blown\u2019 <em>Kelly </em>hearing. [Citation.] \u2018All that is necessary in the limited third-prong hearing is a foundational showing that correct scientific procedures were used.\u2019 [Citation.]\u201d <em>(People </em>v. <em>Morganti, supra, </em>43 Cal.App.4th at pp. 661-662.) Where the prosecution shows that the correct procedures were followed, criticisms of the techniques go to the weight of the evidence, not its admissibility. <em>(People </em>v. <em>Wright </em>(1998) 62 Cal.App.4th 31, 42 [72 Cal.Rptr.2d 246]; <em>People </em>v. <em>Axell </em>(1991) 235 Cal.App.3d 836, 868 [1 Cal.Rptr.2d 411].)</p>\n<p id=\"b623-8\">In <em>People v. Axell, supra, </em>.235 Cal.App.3d 836, the appellant challenged the database used for statistical analysis of a profile match resulting from RFLP-based DNA testing. She claimed, among other things, that Cellmark\u2019s procedure in determining a profile match and in calculating the statistical probability of that match (using an allegedly inadequate database) did not conform to the accepted methodology. The court held that the procedures used were those generally accepted as reliable' in the scientific community. <page-number citation-index=\"1\" label=\"648\">*648</page-number><em>(Id. </em>at p. 862.) As to the matching procedures, the court stated: \u201cSince expert testimony established that Cellmark takes into account a margin of error in its measurement, whether it could or did change its measuring procedures to make them more accurate would appear to go to the weight of the evidence more than its admissibility.\u201d <em>(Id. </em>at p. 864.)</p>\n<p id=\"b624-4\">With regard to the statistical procedures, the court explained that expert witnesses had testified that the database was adequate and acceptable within the scientific community, that other courts had recognized that conservative calculations such as those used by Cellmark may correct any HW deviation problems, and that the loci used were in linkage equilibrium. <em>(People v. Axell, supra, </em>235 Cal.App.3d at pp. 867-868.) The court concluded: \u201cWhere the evidentiary foundation is adequate and statistical independence of the characteristics at issue adequately proved, objection to statistical conclusions goes to weight rather than admissibility. [Citation.] [f] Thus, the prosecution showed that the method used by Cellmark in this case to arrive at its data base and statistical probabilities was generally accepted in the scientific community. Any question or criticism of the size of the data base or the ratio pertains to weight of the evidence and not to its admissibility.\u201d <em>(Id. </em>at p. 868.)</p>\n<p id=\"b624-5\">Similarly, in <em>People </em>v. <em>Wright, supra, </em>62 Cal.App.4th 31, the appellant contended the PCR samples might have been contaminated or confused, and that laboratory procedures should have been more rigorous or controlled. The court stated: \u201c \u2018 \u201cOnce the court acts within its discretion and finds the witness qualified, as it did in this case, the weight to be given the testimony is for the jury to decide.\u201d [Citation.] \u2019 [Citation.] The objections here simply went to the weight, not the admissibility, of this evidence.\u201d <em>(Id. </em>at p. 42.)</p>\n<p id=\"b624-6\">In <em>People </em>v. <em>Venegas, supra, </em>18 Cal.4th 47, the Supreme Court held that the Court of Appeal had erred by failing to uphold one of the trial court\u2019s factual conclusions and by failing to overturn another. On one hand, <em>Venegas </em>determined that the appellate court should have affirmed the trial court\u2019s implied conclusion that a particular expert opinion posed only a question for the jury, which could properly have rejected the opinion in light of substantial contradictory expert testimony. <em>(Id. </em>at p. 91.) On the other hand, <em>Venegas </em>concluded that the appellate court should have found error in the trial court\u2019s determination that the FBI\u2019s failure to follow scientific procedures (by using unduly narrow \u201cbins\u201d in RFLP profiling) was a matter affecting only the weight of the evidence. There was no substantial evidence refuting the expert opinion that the bins were too narrow. The court concluded: \u201cAccordingly, the trial court erred in failing to recognize and rule, based on the testimony presented at the <em>Kelly </em>hearing below, that. . . the FBI did not <page-number citation-index=\"1\" label=\"649\">*649</page-number>follow correct scientific procedures when it calculated [the] random-match probability .... There was no substantial evidence upon which to base a contrary conclusion, and therefore the trial court abused its discretion in not excluding the flawed statistical evidence. [Citations.]\u201d <em>(Id. </em>at p. 93.)</p>\n<p id=\"b625-5\">Applying <em>Venegas </em>here, we must review the trial court\u2019s factual finding\u2014 that proper scientific procedures were followed\u2014for abuse of discretion.</p>\n<p id=\"b625-6\">D. <em>Brown\u2019s Contentions</em></p>\n<p id=\"b625-7\">1. <em>Cellmark\u2019s Database</em></p>\n<p id=\"b625-8\">Brown challenges Cellmark\u2019s use of its African-American database to calculate the frequencies of each of his individual genotypes, which were subsequently multiplied together to arrive at the overall probability of his DNA profile. He argues the prosecution\u2019s expert witnesses established the deficiencies of the database. Brown concludes \u201c[t]he deficiencies in the database deprive the figures generated by Colombo of any scientific validity. It was therefore error for the trial court to overrule the defense objection to the admission of the DNA evidence.\u201d</p>\n<p id=\"b625-9\">The determination of a match\u2019s statistical significance (including HW and linkage equilibria), like the other procedural steps of DNA profiling, is subject to <em>Kelly\u2019s </em>third prong analysis because of its complexity. <em>(People v. Venegas, supra, </em>18 Cal.4th at pp. 83-84.) The court in <em>Venegas </em>explained: \u201c \u2018To . . . leave it to jurors to assess the current scientific debate on statistical calculation as a matter of weight rather than admissibility, would stand <em>Kelly-Frye </em>on its head. We would be asking jurors to do what judges carefully avoid\u2014decide the substantive merits of competing scientific opinion as to the reliability of a novel method of scientific proof. . . . The result would be predictable. The jury would simply skip to the bottom line\u2014the only aspect of the process that is readily understood\u2014and look at the ultimate expression of match probability, without competently assessing the reliability of the process by which the laboratory got to the bottom line. This is an instance in which the method of scientific proof is so impenetrable that it would \u201c \u2018. . . assume a posture of mystic infallibility in the eyes of a jury . . . .\u2019 [Citation.]\u201d [Citations.]\u2019 [Citation.]\u201d <em>(People </em>v. <em>Venegas, supra, </em>18 Cal.4th at pp. 83-84.)</p>\n<p id=\"b625-10\">a. <em>Disequilibria</em></p>\n<p id=\"b625-11\">Brown asserts that Weir\u2019s report acknowledged Cell mark\u2019s African-American database departed from independence at the LDLR locus, depriving the database of HW equilibrium. Brown complains: \u201cDespite the problems noted by Dr. Weir with the LDLR locus, the site is referenced in each <page-number citation-index=\"1\" label=\"650\">*650</page-number>table for the African-American database\u201d; \u201cThe database was not in Hardy-Weinberg equilibrium, and a site examined by the polymarker test was not independent from the remaining locations\u201d; and \u201cThe database was not in Hardy-Weinberg equilibrium [citation], and the LDLR locus tested in this case was not shown to be independent of the remaining locations [citation]. Profile frequency calculations grounded upon this dubious foundation cannot be construed as being obtained by generally accepted and correct scientific procedures.\u201d Brown also maintains that Colombo\u2019s testimony that weaknesses in the database were compensated for by the use of NRCII\u2019s Recommendation 4.1 \u201cdoes not appear to be correct\u201d and the correction Colombo described \u201cwould seem to be illusory.\u201d</p>\n<p id=\"b626-4\">1. <em>Hardy-Weinberg</em></p>\n<p id=\"b626-5\">The evidence established that use of NRCII\u2019s Recommendation 4.1 compensates for deviations from HW equilibrium, particularly when the more conservative value is used in the correction. In his calculations, Weir employed NRCII\u2019s Recommendation 4.1 to compensate for the departures from HW equilibrium he observed at the two loci in Cellmark\u2019s Caucasian and African-American databases. For the LDLR locus in the African-American database, the locus pertinent to this case, Brown was found to have a homozygous genotype of AA. According to Weir, the observed allele frequency (the p value) of the A allele in the African-American database was 0.270. Applying the HW expected proportion of AA = p2, the expected frequency of AA is 0.073, as stated in Table 4a of Weir\u2019s report. If, on the other hand, Recommendation 4.1\u2019s correction is applied using the most conservative (i.e., favoring the defendant) \u00a7 value of 0.03, the expected frequency of AA is p2 + p(l - p)0, resulting in the following calculation:</p>\n<p id=\"b626-6\">AA = 0.073 + 0.270(1 - 0.270)(0.03)</p>\n<p id=\"b626-7\">= 0.079</p>\n<p id=\"b626-8\">This is the result stated by Weir in table 4a under the heading NRC 4.1.</p>\n<p id=\"b626-9\">When the Cellmark analyst calculated Brown\u2019s profile probability, the analyst assigned Brown\u2019s LDLR homozygous AA genotype the frequency of 0.079, the NRCII-recommended value most generous to Brown. This procedure faithfully followed that suggested by Recommendation 4.1 and calculated by Weir. As Fedor testified, Cellmark properly applied Weir\u2019s corrected data in their calculations.</p>\n<p id=\"b626-10\">Brown\u2019s criticism of Colombo\u2019s expert testimony that weaknesses in the database were corrected by use of NRCII\u2019s Recommendation 4.1 is ill-founded. Colombo testified that Recommendation 4.1 corrects for substructuring within ethnic groups, which causes departures from HW equilibrium, <page-number citation-index=\"1\" label=\"651\">*651</page-number>and thereby prevents artificial overestimation of a profile\u2019s rarity. Brown assesses Colombo\u2019s opinion as incorrect and illusory solely because <em>People </em>v. <em>Soto, supra, </em>21 Cal.4th 512 noted that NRCII \u201cexplicitly approves use of the product rule in calculating match frequencies. ([NRCII, <em>supra,] </em>at p. 122 [\u2018Recommendation 4.1: In general, the calculation of a profile frequency should be made with the product rule.\u2019].)\u201d <em>(People </em>v. <em>Soto, supra, </em>21 Cal.4th at p. 539.) From this, Brown apparently concludes Recommendation 4.1 <em>only </em>endorses the product rule.</p>\n<p id=\"b627-5\">The problem with Brown\u2019s stance is threefold. First, <em>Soto </em>discussed whether use of the product rule was appropriate in the case of substructure (a once lively but currently resolved controversy) and referred to Recommendation 4.1 in that context. Second, NRCII\u2019s chapter 4, the source of Recommendation 4.1, addresses not only the product rule but also the correction measures required for population substructure and database size. Chapter 4, entitled Population Genetics, concludes with Recommendation 4.1 (and three other recommendations). The authors introduced chapter 4 with the following summary: \u201cMuch of the controversy about the forensic use of DNA has involved population genetics. In this chapter, we first explain the principles that are generally applicable. We then consider the special problem that arises because the population of the United States includes different <em>population groups and subgroups </em>with different allele frequencies. We develop and illustrate <em>procedures for taking substructure into account in calculating match probabilities. </em>We then show how those procedures can be applied to VNTRs and PCR-based systems.\u201d (NRCII, <em>supra, </em>at p. 89, italics added.)<footnotemark>42</footnotemark></p>\n<p id=\"b627-6\">This summary was followed with equation 4.4a, which was incorporated into Recommendation 4.1 at the end of the chapter. As a note to Recommendation 4.1, NRCII suggested that \u201c[a] more conservative value of 9 = 0.03 might be chosen for <em>PCR-based systems </em>in view of the greater uncertainty of calculations for such systems <em>because of the less extensive and less varied population data </em>than for VNTRs.\u201d (NRCII, <em>supra, </em>at p. 122, italics added; see also <em>id. </em>at p. 119.) Colombo\u2019s testimony therefore agrees with NRCII\u2019s explanation of the reasons for using Recommendation 4.1. Fedor\u2019s testimony also endorsed use of Recommendation 4.1 for these purposes. Fedor, in fact, went further than Colombo by explicitly stating the correction factor also compensated for problems arising from smaller databases.</p>\n<p id=\"b628-3\"><page-number citation-index=\"1\" label=\"652\">*652</page-number>2. <em>Linkage</em></p>\n<p id=\"b628-4\">We believe Brown contends the LDLR locus caused not only a departure from HW equilibrium but also a departure from linkage equilibrium. We base this deduction on these two statements by Brown: \u201ca site examined by the polymarker test was not independent from the remaining locations\u201d and \u201cthe LDLR locus tested in this case was not shown to be independent of the remaining locations.\u201d For support, Brown cites only to a page of Weir\u2019s report, which states: \u201cThere are occasional departures from independence.\u201d</p>\n<p id=\"b628-5\">Weir\u2019s report, however, provides no evidence to support the proposition that the LDLR locus departs from linkage equilibrium. As revealed by \u201cTwo-locus Testing,\u201d Weir found \u201cno evidence of an association between the four allelic frequencies\u201d when sets of two loci were tested for independence of each of the four alleles at those two loci. Brown fails to refer to this analysis by Weir, which explicitly tested for linkage disequilibria and found none. Furthermore, we find no other record evidence supporting Brown\u2019s theory.</p>\n<p id=\"b628-6\">b. <em>Population Not Randomly Collected</em></p>\n<p id=\"b628-7\">Brown next argues certain geographical locations were overrepresented in Cellmark\u2019s African-American database and thus the database was not representative of the relevant population. In particular, he notes 9 of the 100 samples in the database were taken from the Baton Rouge, Louisiana, area. He presumably relies on Fedor\u2019s testimony that overrepresentation of a geographical area can potentially skew the statistics of a small database. Presented with a hypothetical identical to the present case, Fedor explained: \u201cWhat I would suggest is that initially we might have some concern as to whether African-Americans in Baton Rouge happen to constitute a close family grouping. Perhaps because for generations African-Americans have not left Baton Rouge or other African-Americans have not come in to Baton Rouge from elsewhere in the country. That would suggest a common ancestral heritage for African-Americans in Baton Rouge.\u201d</p>\n<p id=\"b628-8\">Thus Fedor identified the questions relevant to determining whether geographical overrepresentation caused allele overrepresentation. The former, however, does not inevitably lead to the latter. Indeed, testimony established most alleles are randomly distributed over geographical regions unless substructure exists in the population, as Fedor explained. If it could have been shown that substructure based on common ancestry existed in the African-American population of Baton Rouge, then he would have been concerned about overrepresentation of certain alleles in the database. Here, however, <page-number citation-index=\"1\" label=\"653\">*653</page-number>there was absolutely no evidence offered to suggest common ancestry existed in Baton Rouge, and Fedor\u2019s response to the hypothetical cannot support Brown\u2019s conclusion.</p>\n<p id=\"b629-5\">c. <em>Inadequate Size</em></p>\n<p id=\"b629-6\">Brown next complains that the 100-person database was too small. Testimony, however, demonstrated that many authorities consider a 100-person database adequate. Fedor, whose company used much larger databases, believed any concerns due to the size of Cellmark\u2019s database were alleviated by the correction factor (Recommendation 4.1) recommended by NRCII and used by Weir. Colombo testified the database was adequate because larger databases would produce the same allelic proportions. She stated a 50-person database could suffice. No evidence countered the testimony that the database size was adequate.<footnotemark>43</footnotemark></p>\n<p id=\"b629-7\">2. <em>Failure to Call Second DNA Analyst</em></p>\n<p id=\"b629-8\">Brown contends the prosecution\u2019s failure to produce DNA analyst Grossweiller to testify as to the PCR testing she performed in this case violated Kelly\u2019s third prong because it was impossible to determine whether Grossweiller used proper scientific procedures.</p>\n<p id=\"b629-9\">Colombo testified Grossweiller followed proper and accepted scientific procedure in her testing. Colombo examined Grossweiller\u2019s report, which, as she explained, was a business record kept in the routine business of Cell-mark. (P<em>eople </em>v. <em>Parker </em>(1992) 8 Cal.App.4th 110, 115-117 [10 Cal.Rptr.2d 38]0<footnotemark>44</footnotemark> Our appellate record discloses no evidence to suggest Colombo\u2019s testimony regarding Grossweiller\u2019s tests was unreliable or that Grossweiller\u2019s lab notes were unreliable as business records.</p>\n<p id=\"b629-10\">We agree with the conclusion of a New Jersey court: \u201cWe reject the notion that the tests were rendered inadmissible because of the State\u2019s failure to call Dr. Blake\u2019s assistant, Ms. Mihalovich. Dr. Blake was permitted to rely on facts or data made known to him prior to his testimony if of a type <page-number citation-index=\"1\" label=\"654\">*654</page-number>reasonably relied on by experts in forming and rendering opinions upon the subject in question. [Citation.] Indeed, an expert\u2019s testimony may be based on the work done or even hearsay evidence of another expert, particularly when, as here, the latter\u2019s work is supervised by the former. [Citation.]\u201d <em>(State v. Dishon </em>(1997) 297 NJ. Super. 254, 280-281 [687 A.2d 1074, 1087].)</p>\n<p id=\"b630-4\">3. <em>Conclusion</em></p>\n<p id=\"b630-5\">As we have explained, the question of whether proper procedures were used to test the DNA and to determine the profile\u2019s statistical significance is a matter going to admissibility, not weight. The trial court found the expert testimony demonstrated that proper scientific procedures had been followed in Brown\u2019s case, thereby satisfying <em>Kelly's </em>third prong and permitting admission of the evidence. The court determined the remaining questions\u2014as to Grossweiller\u2019s DNA testing and the database\u2019s equilibria, randomness, and size\u2014were questions for the jury to consider in weighing the evidence. When reviewing the trial court\u2019s rulings, we defer to the court\u2019s resolutions of credibility and findings of fact. <em>(People v. Glaser </em>(1995) 11 Cal.4th 354, 362 [45 Cal.Rptr.2d 425, 902 P.2d 729].)</p>\n<p id=\"b630-6\">Here, the trial court did not err in finding that the prosecution made the necessary foundational showing that Cellmark was implementing the proper procedures when Grossweiller performed PCR testing of Brown\u2019s DNA and when analysts used Cellmark\u2019s African-American database for statistical interpretation of the data. Expert testimony established that Grossweiller followed proper laboratory procedures, that a 100-person database is acceptable among various authorities in the field and can be used to generalize the entire relevant population, and that Recommendation 4.1 ensures that the frequencies of rare events are not underestimated due to substructure or small database size and that the frequencies are effectively independent. Whether these proper procedures could have been made more accurate goes to weight rather than admissibility. <em>(People </em>v. <em>Wright, supra, </em>62 Cal.App.4th at p. 42; <em>People v. Axell, supra, </em>235 Cal.App.3d at pp. 864, 868.)</p>\n<p id=\"b630-7\">For the reasons we have discussed, therefore, we find no abuse of discretion in the trial court\u2019s ruling. <em>(People </em>v. <em>Venegas, supra, </em>18 Cal.4th at p. 93; <em>People v. Reilly </em>(1987) 196 Cal.App.3d 1127, 1155 [242 Cal.Rptr. 496].) The finding of admissibility is amply supported by substantially uncontroverted evidence.</p>\n<p id=\"b631-4\"><page-number citation-index=\"1\" label=\"655\">*655</page-number>II<footnotemark>*</footnotemark></p>\n<p id=\"b631-5\">disposition</p>\n<p id=\"b631-6\">The judgment is affirmed.</p>\n<p id=\"b631-7\">Buckley, J., and Wiseman, J., concurred.</p>\n<p id=\"b631-8\">Appellant\u2019s petition for review by the Supreme Court was denied November 14, 2001.</p>\n<footnote label=\"1\">\n<p id=\"b602-10\"> All statutory references are to the Penal Code unless otherwise noted.</p>\n</footnote>\n<footnote label=\"2\">\n<p id=\"b602-11\"> Deoxyribonucleic acid.</p>\n</footnote>\n<footnote label=\"3\">\n<p id=\"b602-12\"> The victim went to the hospital for a sexual assault examination. Brown had not used a condom when he had intercourse with the victim. Analysis revealed the presence of semen on the inside and outside of the victim\u2019s vagina. The profile of the DNA from this semen matched Brown\u2019s DNA profile. The DNA analysis and statistical interpretation of the DNA profile were performed by a company known as Cellmark Diagnostics (Cellmark).</p>\n</footnote>\n<footnote label=\"4\">\n<p id=\"b603-9\"> PCR procedures for typing DNA are accepted in the scientific community. <em>(People </em>v. <em>Morganti </em>(1996) 43 Cal.App.4th 643, 666 [50 Cal.Rptr.2d 837] [DQ alpha]; <em>People v. Allen </em>(1999) 72 Cal.App.4th 1093, 1100 [85 Cal.Rptr.2d 655] [STR].) We note, however, that most case law describes the older RFLP (restriction fragment length polymorphism) procedures rather than PCR procedures. (E.g., <em>People </em>v. <em>Venegas, supra, </em>18 Cal.4th 47.)</p>\n</footnote>\n<footnote label=\"5\">\n<p id=\"b603-10\"> There are a few exceptions, the two most significant being red blood cells and sex cells. Red blood cells contain no nucleus and therefore no chromosomes. Egg and sperm cells contain half the number of chromosomes of the rest of the body\u2019s cells, so that upon fertilization the complete number of chromosomes will be restored rattier than doubled. Blood can be used to test a person\u2019s DNA because white blood cells contain DNA; sperm cells can be used because enough cells are tested that collectively the entire complement of DNA is represented. (National Research Council, Com. on DNA Forensic Science: An Update, The Evaluation of Forensic DNA Evidence (1996) p. 12 (hereafter NRCII).)</p>\n</footnote>\n<footnote label=\"6\">\n<p id=\"b604-7\"> The physical characteristic exhibited by the library\u2019s owner generally depends on the dominance or recessiveness of those two descriptions. Paragraphs describing a physical characteristic such as eye color, or describing a particular cellular product or function, are called <em>genes. </em>By definition, they contain a discrete amount of text sufficient to describe a particular thing or function.</p>\n</footnote>\n<footnote label=\"7\">\n<p id=\"b604-8\"> Identical twins, however, share essentially identical DNA.</p>\n</footnote>\n<footnote label=\"8\">\n<p id=\"b605-7\"> This, of course, assumes there was no error in handling of evidence or in laboratory procedure and analysis.</p>\n</footnote>\n<footnote label=\"9\">\n<p id=\"b605-8\"> This probability is often called the random match probability.</p>\n</footnote>\n<footnote label=\"10\">\n<p id=\"b605-9\"> \u201cA determination that the DNA profile of an evidentiary sample matches the profile of a suspect establishes that the two profiles are consistent, but the determination would be of little significance if the evidentiary profile also matched that of many or most other human beings. The evidentiary weight of the match with the suspect is therefore inversely dependent upon the statistical probability of a similar match with the profile of a person drawn at random from the relevant population.\u201d <em>(People </em>v. <em>Venegas, supra, </em>18 Cal.4th at p. 82.)</p>\n</footnote>\n<footnote label=\"11\">\n<p id=\"b606-7\"> Several forensic laboratories in the United States create and utilize their own databases.</p>\n</footnote>\n<footnote label=\"12\">\n<p id=\"b606-8\"> If the ethnicity of the suspect is known, an ethnic database should be used; if the ethnicity is not known, a mixed database should be used. (Recommendation 4.1, NRCII, <em>supra, </em>at p. 122.)</p>\n</footnote>\n<footnote label=\"13\">\n<p id=\"b606-9\"> Probabilities are also often represented in decimal form.</p>\n</footnote>\n<footnote label=\"14\">\n<p id=\"b606-10\"> Obviously, there are situations in which the result of the product rule calculation exceeds the size of the particular population on earth. In that case, the result must be viewed in its alternative sense\u2014the numerical probability that a person randomly chosen from that population will possess the same genetic profile.</p>\n</footnote>\n<footnote label=\"15\">\n<p id=\"b607-8\"> The HW equilibrium formula predicts the frequency of genotypes in a population as follows: p2 + 2pq + q2 = 1, where p = frequency of the A allele, q = frequency of the B allele, p2 = frequency of the AA homozygous genotype, q2 = frequency of the BB homozygous genotype, and 2pq = frequency of the AB heterozygous genotype.</p>\n</footnote>\n<footnote label=\"16\">\n<p id=\"b607-9\"> Random mating, assumed by HW equilibrium, refers to a choice of mate that is independent of ancestry and independent of genotypes at relevant loci. In other words, it assumes people do not choose each other based on their genotypes at the loci used for forensic testing.</p>\n</footnote>\n<footnote label=\"17\">\n<p id=\"b607-10\"> \u201cThe NRC is a private, nonprofit society of distinguished scholars that is administered by the National Academy of Sciences, the National Academy of Engineering and the Institute of Medicine.\u201d <em>(People </em>v. <em>Soto, supra, </em>21 Cal.4th at p. 536, fn. 30.) Many courts have placed great reliance on the NRC reports (e.g., <em>People v. Venegas, supra, </em>18 Cal.4th at p. 89 [\u201cIndeed, \u2018courts have recognized that \u201cthe [NRC] is a distinguished cross section of the scientific community. . . . Thus, that committee\u2019s conclusion regarding the reliability of forensic DNA typing . . . and the proffer of a conservative method for calculating probability estimates can easily be equated with general acceptance of those methodologies in the relevant scientific community.\u201d [Citation.]\u2019 [Citation.]\u201d]), but both the NRC reports and courts\u2019 reliance upon them have been criticized extensively by the scientific community (e.g., Wright, <em>DNA Evidence: Where We\u2019ve Been, Where We Are, and Where We Are Going </em>(1995) 10 Me. B.J. 206, 210 [\u201c[P]erhaps comforted by the convenience of having the NRC Report to cite, some <page-number citation-index=\"1\" label=\"632\">*632</page-number>courts failed to perceive that they were relying on a study which was, as to its method for estimating the expected rarity of a DNA profile, not truly scientific.\u201d]; Kaye, <em>DNA, NAS, NRC, DAB, RFLP, PCR, and More: An Introduction to the Symposium, on the 1996 NRC Report on Forensic DNA Evidence </em>(1997) 37 Jurimetrics J. 395, 404 [\u201cOne lesson to be drawn is that NRC II cannot be assumed to be correct merely because it is a consensus report of a respected organization. And, just as the source of an opinion is not a guarantee of its truth, neither is the certitude with which it is expressed. In airing a range of views on the success and failures of NRC \u00a1H, <em>Jurimetrics </em>shares the aspiration of the authors of that report\u2014to contribute to a wider and deeper understanding of DNA evidence.\u201d]; Balding, <em>Errors and Misunderstandings in the Second NRC Report </em>(1997) 37 Jurimetrics J. 469).</p>\n</footnote>\n<footnote label=\"18\">\n<p id=\"b608-6\"> NRC, Committee on DNA Technology in Forensic Science, DNA Typing: Statistical Basis for Interpretation (1992).</p>\n</footnote>\n<footnote label=\"19\">\n<p id=\"b608-7\"> We note that, in general, much of NRCII\u2019s discussions refer to VNTR (variable number of tandem repeats) testing (which typically refers to RFLP-based tests), with explicit and separate mention of PCR-based tests.</p>\n</footnote>\n<footnote label=\"20\">\n<p id=\"b608-8\"> The NRCH report suggests that the 1992 report, NRCI, \u201cplace[d] too much emphasis on formal statistical significance. In practice, statistically significant departures are more likely to be found in large databases because the larger the sample size, the more likely it is that a small (and perhaps unimportant) deviation will be detected; in a small database, even a large departure might not be statistically significant.... [0]ur approach is different. We explicitly assume that departures from HW proportions exist and use a theory that takes them into account. But ... we expect the deviations to be small.\u201d (NRCII, <em>supra, </em>at pp. 97-98.)</p>\n</footnote>\n<footnote label=\"21\">\n<p id=\"b608-9\"> NRCII\u2019s Recommendation 4.1 states in relevant part: \u201cRecommendation 4.1: In general, the calculation of a profile frequency should be made with the product rule. If the race of the person who left the evidence-sample DNA is known, the database for the person\u2019s race should be used; if the race is not known, calculations for all racial groups to which possible suspects belong should be made. . . . For systems in which exact genotypes can be determined [such as PCR-based systems], p2 + p(l - p)9- should be used for the frequency at such a locus <page-number citation-index=\"1\" label=\"633\">*633</page-number>instead of p2. A conservative value of 9 for the US population is 0.01; for some small, isolation populations, a value of 0.03 may be more appropriate.. . . [2pq] should be used for heterozygotes.\u201d (NRCII, <em>supra, </em>at p. 122.)</p>\n<p id=\"b609-12\">NRCII also noted that \u201ccorrecting for population structure should make little difference, and the procedures outlined in [the NRCII report] can be expected to give fair estimates of the range of uncertainty in population and subpopulation frequency estimates for discrete allele systems.\u201d (NRCII, <em>supra, </em>at p. 188.)</p>\n</footnote>\n<footnote label=\"22\">\n<p id=\"b610-7\"> NRCB notes that \u201ccomparisons between [short tandem repeats of] geographical and racial groups show similarities and differences comparable to those of VNTRs.\u201d (NRCII, <em>supra, </em>at p. 34.)</p>\n</footnote>\n<footnote label=\"23\">\n<p id=\"b611-7\"> For instance, with larger samples the agreement with HW proportions is expected to be better. (NRCII, <em>supra, </em>at p. 93.)</p>\n</footnote>\n<footnote label=\"24\">\n<p id=\"b611-8\"> Editorial (1992) 52 Forensic Sci. Internal 125-130.</p>\n</footnote>\n<footnote label=\"25\">\n<p id=\"b611-9\"> Sensabaugh, <em>Biochemical Markers of Individuality </em>in Forensic Science Handbook (1982) at page 391.</p>\n</footnote>\n<footnote label=\"26\">\n<p id=\"b611-10\"> NRCI, <em>supra, </em>at pages 74-96.</p>\n</footnote>\n<footnote label=\"27\">\n<p id=\"b611-11\"> NRCH, <em>supra, </em>at pages 20-26.</p>\n</footnote>\n<footnote label=\"28\">\n<p id=\"b611-12\"> Lander and Banbury, DNA Technology and Forensic Science (1989) at pages 143-156.</p>\n</footnote>\n<footnote label=\"29\">\n<p id=\"b611-13\"> Devlin et al., <em>Statistical Evaluation of DNA Fingerprinting: A Critique of the NRC\u2019s Report </em>(Feb. 5, 1993) 259 Sci. 748, 749, 837.</p>\n</footnote>\n<footnote label=\"30\">\n<p id=\"b611-14\"> Devlin et al., <em>Comments on the Statistical Aspects of the NRC\u2019s Report on DNA Typing </em>(1994) 39 J. Forensic Sci. 28-40.</p>\n</footnote>\n<footnote label=\"31\">\n<p id=\"b612-5\"> Lander and Budowle, <em>DNA Fingerprinting Dispute Laid to Rest </em>(1994) 371 Nature 735-738.</p>\n</footnote>\n<footnote label=\"32\">\n<p id=\"b612-6\"> Weir, <em>Population Genetics in the Forensic DNA Debate </em>(1992) 89 Proc. Nat. Acad. Sci. USA 11654-11659.</p>\n</footnote>\n<footnote label=\"33\">\n<p id=\"b612-7\"> Pacek et al., <em>Determination of Allele Frequencies at Loci with Length Polymorphism by Quantitative Analysis of DNA Amplified from Pooled Samples </em>(1993) 2 PCR Meth. Appl. 313-317.</p>\n</footnote>\n<footnote label=\"34\">\n<p id=\"b612-8\"> Harding and Swanson suggest a database does indeed reach a size at which its allele frequencies no longer change (i.e., their plotted frequencies level out). At that point, the database is likely adequate to offer reliable allele frequency estimates. The required database size will vary with the loci tested in the database. For example, one set of seven loci test\u00e9d by Harding and Swanson achieved level plots, and presumably adequate database size, at 100 persons; another set of eight required 170 to 180 people. <em>(DNA Database Size, supra, </em>41 J. Forensic Sci. at pp. 248-249.)</p>\n</footnote>\n<footnote label=\"35\">\n<p id=\"b612-9\"> Some sources suggest calculating a confidence interval (similar to a margin of error) is helpful to qualify a profile\u2019s probability. (E.g., NRCII, <em>supra, </em>at pp. 34, 112, 125 [\u201cIf the database is small, the values derived from it can be uncertain even if it is compiled from a scientifically drawn sample; this can be addressed by providing confidence intervals on the estimates.\u201d], 146, 156; <em>Reference Guide on DNA Evidence, supra, </em>at p. 557 [\u201c[J]ust as pollsters present their results within a certain margin of error, the expert should be able to explain the extent of the statistical error that arises from using samples of the size of the forensic database.\u201d (Fn. omitted.)].) NRCII stated: \u201cIt is probably safe to assume that within a race, the uncertainty of a value calculated from adequate databases ... by the product rule is within a factor of about 10 above and below the true value. If the calculated profile probability is very small, the uncertainty can be larger, but even a large relative error will not change the conclusion.\u201d (NRCII, <em>supra, </em>at p. 156.) A smaller database produces a wider confidence interval; the width of the interval on the log scale is inversely proportional to the square root of the size of the database. <em>(Id. </em>at p. 147.) Other scientists have argued that confidence limits are not necessary \u201cbecause the procedure for allele estimation is sufficiently \u2018conservative\u2019 to overestimate the frequency of matching alleles even without such a correction.\u201d (Thompson, <em>Evaluating the Admissibility of New Genetic Identification Tests: Lessons from the \u201cDNA War\u201d </em>(1993) 84 J. Crim. L. &amp; Criminology 22, 67, fn. omitted.)</p>\n</footnote>\n<footnote label=\"36\">\n<p id=\"b614-9\"> AIso sometimes called DQ alpha.</p>\n</footnote>\n<footnote label=\"37\">\n<p id=\"b614-10\"> Weir also commented that, in cases of deviations from independence, \u201can alternative to NRC Recommendation 4.1 is to use observed genotypic proportions at single loci. This approach could be adopted for LDLR [low density lipoprotein receptor] in the African American database and GC [group-specific component] in the Caucasian database.\u201d Weir did not apply this approach, but followed the NRC guidelines.</p>\n</footnote>\n<footnote label=\"38\">\n<p id=\"b614-11\"> The LDLR and GC loci are associated with functional genes and the variability between races is greater. (NRCII, <em>supra, </em>at pp. 118-119.)</p>\n</footnote>\n<footnote label=\"39\">\n<p id=\"b615-9\"> Weir\u2019s report indicates 103 Caucasians were used.</p>\n</footnote>\n<footnote label=\"40\">\n<p id=\"b618-11\"> The \u201ccoancestry coefficient\u201d to which Fedor refers is the correction factor of Recommendation 4.1.</p>\n</footnote>\n<footnote label=\"41\">\n<p id=\"b622-9\"><em> Frye v. United States </em>(D.C. Cir. 1923) 293 Fed. 1013 [34 A.L.R. 145].</p>\n</footnote>\n<footnote label=\"42\">\n<p id=\"b627-7\"> See also Modem Scientific Evidence, <em>supra, </em>at page 646 (\u201cthe dispute about the \u2018product rule\u2019 centers on the degree of population structure and the effect that it could have\u201d); NRCII, <em>supra, </em>at page 102 (\u201cWe can deal with a structured population by using a theory that is very similar to that of inbreeding. . . .\u201d).</p>\n</footnote>\n<footnote label=\"43\">\n<p id=\"b629-11\"> There was no evidence suggesting that use of confidence intervals was necessary.</p>\n</footnote>\n<footnote label=\"44\">\n<p id=\"b629-12\"> The trial court was obviously satisfied as to the trustworthiness of the laboratory reports prepared by Brenda Smith, a criminalist employed by the Kern County Regional Laboratory, based on the testimony of Jeanne Spencer identifying the reports and detailing the tests and procedures used by all criminalists employed by the laboratory, that said procedures were standard in the industry, and that Ms. Smith\u2019s notes indicated she had followed the normal procedures. The court\u2019s implied finding of trustworthiness is amply supported by sufficient evidence independent of the reports themselves. The trial court did not abuse its discretion by admitting the reports [under the business record exception to the hearsay rule].\u201d <em>(People v. Parker, supra, </em>8 Cal.App.4th at p. 117.)</p>\n</footnote>\n<footnote label=\"*\">\n<p id=\"b631-9\"> See footnote, <em>ante, </em>page 623.</p>\n</footnote>\n</opinion>\n</casebody>\n",
    "status": "ok"
  }
}