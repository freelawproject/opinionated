{
  "casebody": {
    "data": "<casebody firstpage=\"38\" lastpage=\"56\" xmlns=\"http://nrs.harvard.edu/urn-3:HLS.Libr.US_Case_Law.Schema.Case_Body:v1\">\n<otherdate data-order=\"0\" data-type=\"otherdate\" id=\"b58-2\">Argued and submitted August 19, 2014,</otherdate>\n<decisiondate data-order=\"1\" data-type=\"decisiondate\" id=\"ApE\">affirmed May 13,</decisiondate>\n<otherdate data-order=\"2\" data-type=\"otherdate\" id=\"AZD\">petition for review denied October 9, 2015 (358 Or 70)</otherdate>\n<parties data-order=\"3\" data-type=\"parties\" id=\"b58-3\">STATE OF OREGON, <em>Plaintiff-Respondent, v. </em>NATHAN COMBEST, <em>Defendant-Appellant.</em></parties>\n<p data-order=\"4\" data-type=\"court\" id=\"b58-5\">Lane County Circuit Court</p>\n<docketnumber data-order=\"5\" data-type=\"docketnumber\" id=\"AW\">201203470; A151950</docketnumber>\n<citation data-order=\"6\" data-type=\"citation\" id=\"b58-6\">350 P3d 222</citation>\n<attorneys data-order=\"7\" data-type=\"attorneys\" id=\"b58-10\">Mary M. Reese, Senior Deputy Public Defender, argued the cause for appellant. With her on the brief was Peter Gartlan, Chief Defender, Office of Public Defense Services.</attorneys>\n<attorneys data-order=\"8\" data-type=\"attorneys\" id=\"b58-11\">Michael J. Slauson, Senior Assistant Attorney General, argued the cause for respondent. With him on the brief were Ellen F. Rosenblum, Attorney General, and Anna M. Joyce, Solicitor General.</attorneys>\n<judges data-order=\"9\" data-type=\"judges\" id=\"b59-3\"><page-number citation-index=\"1\" label=\"39\">*39</page-number>Before Sercombe, Presiding Judge, and Hadlock, Judge, and Tookey, Judge.</judges>\n<judges data-order=\"10\" data-type=\"judges\" id=\"b59-4\">SERCOMBE, P. J.</judges>\n<opinion data-order=\"11\" data-type=\"opinion\" id=\"x999-1\" type=\"majority\">\n<author id=\"b60-3\"><page-number citation-index=\"1\" label=\"40\">*40</page-number>SERCOMBE, P. J.</author>\n<p id=\"b60-4\">Defendant appeals a judgment of conviction for multiple counts of encouraging child sexual abuse, assigning error to the trial court\u2019s denial of his motion to suppress evidence. Defendant shared files, including files containing child pornography, on a peer-to-peer computer network. Using software called Shareaza LE, officers accessed that peer-to-peer network; searched for shared files that, in light of file name and other attributes, were likely child pornography; identified an IP address for a user sharing those files; and then downloaded two files from that user. They later identified defendant as that user and uncovered other evidence from defendant\u2019s computer that he possessed child pornography. On appeal, defendant argues, as he did in the trial court, that all evidence of his distribution and possession of child pornography should be suppressed because the officers conducted a warrantless \u201csearch\u201d under Article I, section 9, of the Oregon <em>Constitution</em><footnotemark><em>1</em></footnotemark><em> </em>\u2014 i.e., they invaded defendant\u2019s protected privacy interest \u2014 when they used Shareaza LE to locate and access his files on the peer-to-peer network. As detailed below, we conclude that, because the officers used Shareaza LE to access selective information that defendant made available to any other user of the peer-to-peer network by targeting shared network files containing child pornography, their use of that software did not amount to a search under Article I, section 9. Accordingly, we affirm.</p>\n<p id=\"b60-5\">We review the trial court\u2019s denial of defendant\u2019s motion to suppress for legal error, and we describe the facts consistently with the trial court\u2019s explicit and implicit findings, which the evidence supports. <em>State v. Ehly, </em>317 Or 66, 75, 854 P2d 421 (1993). We start by detailing the operation of Shareaza LE, as explained by a detective and a forensics analyst from the Lane County Sheriffs Office, before describing how they used that software in this case.</p>\n<p id=\"b60-6\">Peer-to-peer file sharing permits a computer user to share files with other users on a particular peer-to-peer <page-number citation-index=\"1\" label=\"41\">*41</page-number>network. To access the peer-to-peer network that defendant used in this case, eDonkey, a user must download client application software. Defendant used software called eMule. That software allows a user to search all the files that other online network users are sharing by entering search terms. A user is online if he has logged into eMule and has it running on his computer; the number of users running eMule at any given time ranges from several hundred thousand to many million.</p>\n<p id=\"b61-4\">After a user enters search terms, eMule creates a list of results, and a user can then click on a file to download. When downloading a file, eMule puts the file immediately into a \u201cTemp\u201d folder; when a file is completely downloaded, eMule moves the file to an \u201cIncoming\u201d folder. The eMule software automatically creates those folders, and the files in those folders are automatically shared with other users on the network. A user can prevent other users from gaining access to a downloaded file by moving that file out of the Temp or Incoming folders on the user\u2019s computer. But downloaded files that remain in those folders are available for download by other users.</p>\n<p id=\"b61-5\">The peer-to-peer network, eDonkey, \u201chashes\u201d the files on the network; that is, it uses a complex mathematical algorithm to generate an alphanumeric identifier \u2014 a hash value \u2014 unique to each file. One of the officers in this case described a hash value as \u201cmore accurate than DNA.\u201d<footnotemark>2</footnotemark> He testified that, if a user downloaded a digital picture and \u201cremove [d] one pixel out of that, the whole hash value changes.\u201d But if a user changes the file name without changing the file itself, the hash value stays the same. Two files that are exactly the same (even if they have different file names) will have the same hash value.</p>\n<p id=\"b61-6\">Hash values are therefore useful to police officers who monitor peer-to-peer networks for the exchange of child <page-number citation-index=\"1\" label=\"42\">*42</page-number>pornography.<footnotemark>3</footnotemark> The National Center for Missing and Exploited Children (NCMEC) keeps a list of the hash values of shared files \u2014 pictures and videos \u2014 that are known to contain child pornography. One way for law enforcement to quickly identify files that contain child pornography, then, is to look for hash values that match those on the NCMEC list, because hash values stay constant as the same file is copied and exchanged, even if the file name is changed.</p>\n<p id=\"b62-4\">In this case, the Lane County Sheriffs Office used software called Shareaza LE to find files on the eDonkey network that it suspected contain child pornography. Shareaza LE performs an automated search for child pornography by automatically ticking through and entering a rotating list of search terms commonly used to obtain child pornography. For the files that match those search terms, Shareaza LE goes through a \u201cvetting\u201d process and targets those files that have a hash value identified by the NCMEC as \u201cchild notable.\u201d</p>\n<p id=\"b62-5\">Shareaza LE narrows its search to a particular jurisdiction. It does this by identifying the Internet Protocol (IP) address associated with users on the network and narrowing its search to a particular set of IP addresses. An IP address is a unique number assigned by an Internet Service Provider (ISP) like Comcast or Charter Cable to a customer\u2019s modem, and police can generally track particular IP addresses to a particular geographic region.<footnotemark>4</footnotemark> Assuming that a customer has only one ISP, the customer has one IP address, no matter how many devices are connected to the Internet using that service. Because Shareaza LE can narrow its search to IP addresses in a particular region, officers <page-number citation-index=\"1\" label=\"43\">*43</page-number>do not have to \u201csearch thousands and thousands\u201d of files to find one with an IP address in their jurisdiction.</p>\n<p id=\"b63-4\">Besides the IP address, Shareaza LE identifies the Globally Unique Identifier (GUID) given to a specific computer on the peer-to-peer network. In contrast to an IP address, the GUID is specific to a particular user\u2019s eMule software installed on a particular computer. Because the probability of two eMule software applications having the same GUID is extremely small, officers can confidently match the GUID from a downloaded file containing child pornography with the GUID of particular eMule software on a computer.</p>\n<p id=\"b63-5\">Once an officer finds a specific file with a particular IP address to download, the officer uses Shareaza LE to download that file from the user at that IP address. In that respect, Shareaza LE is different than other software, like eMule, that takes pieces of that file from multiple users in order to speed up the download process.</p>\n<p id=\"b63-6\">In sum, Shareaza LE searches for files that are likely to contain child pornography (by file name and hash value), and it narrows the search results to network users in a particular geographic region (by IP address). Once a file of interest is found, Shareaza LE downloads that file from a single user (identified by the user\u2019s GUID). That information \u2014 the IP address, file name, hash value, and GUID \u2014 and the date and time of download are logged. As one of the officers explained, although Shareaza LE \u201cdoes a little bit more extensive logging than the normal [file-sharing] software,\u201d it \u201cdoesn\u2019t do anything intrusively to get anything.\u201d Shareaza LE logs \u201cthe information that\u2019s presented from establishing that peer-to-peer connection.\u201d For example, with respect to the GUID that matches a user\u2019s eMule software, that GUID is shared when one user\u2019s eMule software exchanges files with another user\u2019s eMule software. As for the IP address, one of the officers explained that at least some peer-to-peer software applications display the IP address of the network computers possessing a file available for download.</p>\n<p id=\"b63-7\">Here, a forensics analyst for Lane County, Caffee, used Shareaza LE to identify a user with an IP address in <page-number citation-index=\"1\" label=\"44\">*44</page-number>Lane County who was sharing files on the eDonkey network with hash values that matched hash values identified by the NCMEC as child pornography.<footnotemark>5</footnotemark> On October 19, 2011, Caffee downloaded two files from that user. In doing so, Caffee obtained the GUID for the eMule software that was sharing those files. Caffee wrote a report and forwarded it to a detective, Hoberg, who determined that the two files (both videos) depicted sexually explicit conduct involving children.</p>\n<p id=\"b64-4\">Using a publicly available website that identifies an ISP based on an IP address,<footnotemark>6</footnotemark> Hoberg determined that Charter Cable controlled the IP address in Lane County that Caffee identified, and he served a grand jury subpoena on Charter Cable to obtain the name and service address of the customer assigned to the IP address. Charter Cable provided the police with a name and physical address, and Hoberg then obtained a search warrant for that address.</p>\n<p id=\"b64-5\">When Hoberg executed the warrant, he learned that defendant lived at the address. After Hoberg provided defendant <em>Miranda </em>warnings, defendant told him that he \u201cprobably\u201d downloaded child pornography using eMule. Defendant further explained that he was trying to obtain adult pornography and tried to avoid any child pornography. He stated that, when using eMule, he selects several videos to download but does not look at individual file names before downloading.</p>\n<p id=\"b64-6\">Hoberg seized defendant\u2019s computer. When Caffee searched the operable hard drive of that computer, he found eMule software and matched its GUID to the GUID for the two files that Caffee downloaded. Caffee found two other complete video files containing child pornography in the eMule Temp folder on defendant\u2019s computer, and he found another child pornography file (an image) in the desktop recycle bin on defendant\u2019s computer, which had not been emptied. Caffee also found the search history for defendant\u2019s eMule software and identified search terms commonly associated with child pornography.</p>\n<p id=\"b65-3\"><page-number citation-index=\"1\" label=\"45\">*45</page-number>Defendant was charged with two counts of first-degree encouraging child sexual abuse, ORS 163.684, relating to the two video files Caffee downloaded from defendant on the network, and three counts of second-degree encouraging child sexual abuse, ORS 163.686, relating to the other three files found on defendant\u2019s computer.<footnotemark>7</footnotemark></p>\n<p id=\"b65-4\">Defendant filed a motion to suppress the evidence obtained by the \u201cwarrantless search\u201d of the eDonkey peer-to-peer network <em>(i.e., </em>the IP address and other information obtained by Shareaza LE) and all derivative evidence (defendant\u2019s statements to police and evidence obtained as a result of the computer search). Defendant argued that Shareaza LE was equivalent to \u201csurreptitious government surveillance\u201d of his private communications on a peer-to-peer network:</p>\n<blockquote id=\"b65-5\">\u201cLike a phone line, eMule, Gnutella, any of the other file sharing programs allow a form of communication between people, and what the State is saying is that there is no right to privacy in that which may be communicated along that phone line.</blockquote>\n<blockquote id=\"b65-6\">\u201cThe GUID, the IP address, it\u2019s a communication. If a police officer wants to tap someone\u2019s phone, they need a warrant. They can\u2019t create a global, all-encompassing phone-tap machine and then say, but, we filtered it out, so it only picks out these specific words, so it only picks [terms commonly used to search for child pornography]. They can\u2019t do it because it\u2019s too much of an invasion of privacy.</blockquote>\n<blockquote id=\"b65-7\">\u201cReally, I think the cases here show that it\u2019s not always enough to say: (1) that this information is available to third parties; therefore, it\u2019s freely available to the police <page-number citation-index=\"1\" label=\"46\">*46</page-number>however they choose to get it; and (2), there\u2019s a clear hostility towards this sort of surveillance * * * towards 24-hour non-human surveillance without a warrant.\u201d</blockquote>\n<p id=\"b66-4\">With respect to \u201cnon-human surveillance,\u201d defendant contrasted an officer\u2019s on-the-street surveillance with \u201cinvasive\u201d surveillance by \u201cmeans of technology\u201d that courts had determined to be a \u201csearch,\u201d <em>e.g., </em>\u201cGPS tracking\u201d and \u201cthermal imaging of homes.\u201d Defendant argued that, like those government activities, \u201cthe government\u2019s current system for gathering information constitutes searching in and of itself\u2019 and \u201csimply goes too far.\u201d</p>\n<p id=\"b66-5\">In response, the state argued that defendant had no privacy interest in the information police obtained using Shareaza LE. That conclusion was warranted, in the state\u2019s view, because defendant \u201cmade the decision to join a public file-sharing network for the purpose of sharing, in his case, child pornography.\u201d And the state asserted that the officer\u2019s activity was \u201cjust like anybody else\u2019s. I could go onto eMule and I could find any number of individuals that were distributing child pornography, just as a user. There [are] no privacy interests there.\u201d</p>\n<p id=\"b66-6\">After hearing those arguments, the trial court denied defendant\u2019s motion:</p>\n<blockquote id=\"b66-7\">\u201cWhile there are many different permutations and considerations from many different angles, I think at the heart of it is this, [defendant] availed himself of a public networking peer-to-peer computer program that gave him access, knowingly, to countless other people who did the same.</blockquote>\n<blockquote id=\"b66-8\">\u201cThat act and engaging in this network subjected himself to public viewing and evaluation by anybody who wished to be part of that network, and as such there was no violation of one\u2019s right to privacy by having law enforcement do the same.\u201d</blockquote>\n<p id=\"b66-9\">Defendant later entered a conditional guilty plea for all crimes charged, preserving an appellate challenge to the trial court\u2019s denial of his motion to suppress.</p>\n<p id=\"b66-10\">On appeal, defendant again argues that the police engaged in a warrantless search under Article I, section 9, when they used Shareaza LE. Defendant contends that, <page-number citation-index=\"1\" label=\"47\">*47</page-number>even though his IP address and activity on the network were exposed to other network users, the officers in this case invaded a protected privacy interest by obtaining that information because <em>\u201ca </em>network user does not need or use that information to download a file\u201d and would \u201chave no reason to expect that another [network] participant will deliberately identify [that user\u2019s] IP address.\u201d Defendant further argues that Shareaza LE, which he calls \u201cadvanced computer technology,\u201d represented an invasion of privacy because it allowed the police to conduct \u201ccontinuous, minute scrutiny of Internet activity, log data regarding that activity into a database that permits them to zero in on a specific computer user in a specific place at a specific time, and investigate and capture the content of an individual computer user\u2019s shared files.\u201d<footnotemark>8</footnotemark></p>\n<p id=\"b67-4\">The state responds that the police did not conduct a search when they used software to identify and download files from his computer that he had made publicly available to other users of the file-sharing network. Shareaza LE, the state emphasizes, \u201cexposed nothing more than what defendant chose to make public by using the file-sharing network.\u201d In the state\u2019s view, \u201cthe proper inquiry for constitutional purposes is not whether the technology used by police is \u2018advanced,\u2019 but whether the police used technology to observe what would otherwise be unobservable without the technology.\u201d<footnotemark>9</footnotemark></p>\n<p id=\"b68-3\"><page-number citation-index=\"1\" label=\"48\">*48</page-number>The parties\u2019 competing arguments reflect familiar Article I, section 9, principles. A \u201csearch\u201d under Article I, section 9, occurs when \u201cthe government invades a protected privacy interest.\u201d <em>State v. Meredith, </em>337 Or 299, 303, 96 P3d 342 (2004). We determine whether the government invaded a person\u2019s protected privacy interest \u201cby an objective test of whether the government\u2019s conduct \u2018would significantly impair an individual\u2019s interest in freedom from scrutiny, <em>i.e., </em>his privacy.\u2019\u201d <em>State v. Wacker, </em>317 Or 419, 425, 856 P2d 1029 (1993) (quoting <em>State v. Dixson/Digby, </em>307 Or 195, 211, 766 P2d 1015 (1988)). \u201cThe threshold question in any Article I, section 9, search analysis is whether the police conduct at issue is sufficiently intrusive to be classified as a search.\u201d <em>Id. </em>at 426. Here, then, we must determine whether the officers\u2019 use of Shareaza LE to seek out and download files from defendant on a peer-to-peer network \u2014 and to obtain the IP address, GUID, and hash value associated with those files \u2014 invaded defendant\u2019s protected privacy interest and was thus \u201csufficiently intrusive to be classified as a search.\u201d <em>Id.</em></p>\n<p id=\"b68-4\">Although that question cannot be answered by close factual analogy to our precedents under Article I, section 9,<footnotemark>10</footnotemark> <page-number citation-index=\"1\" label=\"49\">*49</page-number>we find two cases particularly instructive in applying that provision to an officer\u2019s use of software to access files shared on a peer-to-peer network: <em>State v. Campbell, </em>306 Or 157, 759 P2d 1040 (1988), and <em>Wacker. </em>Each involved police use of technology to collect or record information about a suspect, and, in each, the Supreme Court considered police observation of conduct that was, at least arguably, observable by others.</p>\n<p id=\"b69-4\">In <em>Campbell, </em>officers suspected that the defendant was involved in several burglaries, and they attached a transmitter to the defendant\u2019s car while it was parked in a public parking lot. 306 Or at 159-60. By tracking radio waves emitted by the transmitter from a small airplane, the officers were able to monitor the movement of the car over the course of several days, and they eventually located the car at a residence that had been burglarized. The Supreme Court concluded that the use of the radio transmitter to locate the defendant\u2019s car amounted to a search under Article I, section 9. The court explained that the \u201cuse of a radio transmitter to locate an object to which the transmitter is attached cannot be equated with visual tracking\u201d \u2014 the police had failed to visually monitor the defendant\u2019s car without detection. <em>Id. </em>at 171-72. And the court reasoned that \u201c[a]ny device that enables the police to quickly locate a person or object anywhere within a 40-mile radius, day or night, over a period of several days, is a significant limitation on freedom from scrutiny.\u201d <em>Id. </em>at 172.</p>\n<p id=\"b69-5\">In <em>Wacker, </em>after receiving complaints from a tavern owner of drug activity in the area, officers used a video camera and starlight scope (a device that magnified images and helped officers see better in the dark) to observe the defendant and others inside a car parked in the tavern <page-number citation-index=\"1\" label=\"50\">*50</page-number>parking lot. 317 Or at 421. In concluding that the officers had not conducted a search under Article I, section 9, the court observed that the defendant \u201cchose to carry out his activities in the parking lot of a tavern that was open for business\u201d while he was \u201cin a car with its console or overhead light on.\u201d <em>Id. </em>at 427-28. Although the police observed the defendant at night, his conduct was visible to passersby and to the officers who were stationed 29 feet away. Rejecting the notion that <em>Campbell </em>\u201cestablish [ed] a <em>per se </em>rule against the warrantless use by police of any technologically enhanced observation regardless of the circumstances,\u201d <em>id. </em>at 426 n 12, the court concluded that the \u201copen-to-the-public nature of defendant\u2019s * * * location and activities in a lighted car in a tavern parking lot during business hours establishes that no government conduct significantly impaired defendant\u2019s privacy,\u201d <em>id. </em>at 427.</p>\n<p id=\"b70-4\">In comparing the police conduct in <em>Campbell </em>and <em>Wacker, </em>there are two constitutionally significant distinctions that are instructive here. First, the conduct that the police observed in <em>Wacker </em>was available to public observers in a way that the information the police gained from the transmitter in <em>Campbell </em>was not. In <em>Wacker, </em>the officers\u2019 use of a starlight scope and camcorder to aid and record their observations did not amount to a search because the officers used those devices to observe conduct that was observable by any passerby in the parking lot. In <em>Campbell, </em>though, the court rejected the contention that \u201cthe transmitter disclosed only what any member of the public could legitimately have observed.\u201d 306 Or at 165. The officers in that case had failed to track the defendant\u2019s car through visual surveillance, and it would be impossible for the police or the public to observe the kind of information that the transmitter provided. <em>See </em>Wayne R. LaFave, 1 <em>Search and Seizure </em>\u00a7 2.7(f), 999 (5th ed 2012) (criticizing the notion that a radio transmitter attached to a car traveling on public roads reveals the same information that any member of the public would observe because \u201c[o]nly an army of bystanders, conveniently strung out on [the defendant\u2019s] route and who not only \u2018wanted to look\u2019 but also wanted to pass on what they observed to the next in line, would * * * \u2018have sufficed to reveal all of these facts to the <page-number citation-index=\"1\" label=\"51\">*51</page-number>police\u2019\u201d).<footnotemark>11</footnotemark> In other words, the conduct that the police observed was only nominally public; the transmitter gave the officers access to information that was materially different than the information the defendant broadcast to those who could see him traveling in his car.</p>\n<p id=\"b71-4\">Second, and relatedly, to the extent that <em>Campbell </em>and <em>Wacker </em>both considered official observation of conduct in a public place, the surveillance in <em>Campbell </em>was of a dramatically different scope and intensity than that in <em>Wacker. </em>In <em>Wacker, </em>the officers\u2019 surveillance was targeted to detecting drug activity in a particular tavern parking lot. The court was emphatic that the defendant \u201cchose to carry out his activities\u201d in a lighted car in that public space. 317 Or at 426. By contrast, the transmitter in <em>Campbell </em>allowed the police to conduct pervasive surveillance of the defendant: Day and night, over a period of several days, the officers could track the defendant\u2019s movements within a 40-mile radius, whether his vehicle was on a busy city street or a secluded highway. 306 Or at 172. Given the breadth of information that the police learned from the transmitter, the court reasoned that, if police could use the transmitter without limitation, \u201cno movement, no location, and no conversation in a public place would in any measure be secure from prying of the government.\u201d<footnotemark>12</footnotemark> <em>Id.</em></p>\n<p id=\"b72-3\"><page-number citation-index=\"1\" label=\"52\">*52</page-number>In subsequent cases, the Supreme Court has highlighted both the not-truly-public nature of the information that the transmitter in <em>Campbell </em>collected and the extensive surveillance that the transmitter allowed. In <em>Meredith, </em>where the court concluded that police did not conduct a search when they attached a transmitter to a public employee\u2019s publicly owned car, the court explained that</p>\n<blockquote id=\"b72-4\">\u201c[t]he officers [in Campbell] subjected the defendant and his vehicle to pervasive and constant examination of his movements and location throughout his daily life. In the same way that electronically eavesdropping on public conversations would enable the police to gain information that, although nominally public, was not normally available to a passerby, the police monitoring of the transmitter allowed the government to observe a range of conduct that normally would have been inaccessible to the general public or to government officials.\u201d</blockquote>\n<p id=\"b72-5\">337 Or at 306-07 (reasoning that the defendant, as a public employee, \u201cdid not have a protected privacy interest in keeping her location and work-related activities concealed from the type of observation by her employer that the transmitter revealed\u201d). In this case, those same considerations compel the conclusion that the officers\u2019 conduct \u2014 the use of Shareaza LE on a peer-to-peer network \u2014 was not sufficiently intrusive to be classified as a search.</p>\n<p id=\"b72-6\">First, the officers obtained the same information with Shareaza LE that was available to other network users. When defendant made files available for download on the eDonkey network, defendant made the IP address and GUID associated with those files available to other users. Whereas the transmitter in <em>Campbell </em>gave police access to information about the defendant that was \u201cinaccessible to the general public or to government officials\u201d \u2014 the location of the defendant\u2019s car at any time over a span of several days \u2014 here the information that the police observed using Shareaza LE is the same information that any user with file sharing software could access. <em>Meredith, </em>337 Or at 307. And that information was available to the officers, as it was to other users of the network, because defendant chose to share files with those users, just like the defendant <page-number citation-index=\"1\" label=\"53\">*53</page-number>in <em>Wacker </em>chose to carry out his activities in a place where others could see it.<footnotemark>13</footnotemark></p>\n<p id=\"b73-4\">Second, the officers used Shareaza LE to seek out files containing child pornography that users were sharing on a peer-to-peer network; that technology did not allow the \u201cpervasive and constant examination of [defendant\u2019s online activity] throughout his daily life\u201d as the transmitter in <em>Campbell </em>did with respect to the defendant\u2019s movements. Indeed, the police conduct here was more like the limited observation of particular conduct that was not a search in <em>Wacker. Meredith, </em>337 Or at 307. The officers here used Shareaza LE to target files of child pornography that users made available on the network, and the officers then downloaded two of those files from a particular user (who was later identified as defendant). In doing so, it was not necessary for police to engage in constant, prolonged observation of defendant\u2019s conduct on the network.</p>\n<p id=\"b73-5\">Defendant responds with two arguments. With respect to the proposition that he had no privacy interest in the information he made available to others on the network, defendant argues that he expected to remain anonymous to other network users, who were simply interested in downloading his files. That is, defendant asserts that, even though he made his IP address and other information available when he shared files, he had \u201cno reason to expect that another participant [would] deliberately identify [his] IP address\u201d or \u201clog [his] activity on the network.\u201d We disagree.</p>\n<p id=\"b73-6\">The Supreme Court has repeatedly rejected the notion that a person\u2019s \u201csubjective expectation of privacy * * * necessarily determine [s] whether a privacy interest has been violated.\u201d <em>State v. Brown, </em>348 Or 293, 298, 232 P3d 962 (2010). In <em>State v. Howard/Dawson, </em>342 Or 635, 643, <page-number citation-index=\"1\" label=\"54\">*54</page-number>157 P3d 1189 (2007), for example, the court concluded that the defendants did not retain a privacy interest in garbage that they turned over to a sanitation company without any restriction on its disposal, even though the defendants \u201cdid not expect that the sanitation company would look through their garbage or permit someone else to do so.\u201d We applied that same principle in <em>State v. Carle, </em>266 Or App 102, 110, 337 P3d 904 (2014), <em>rev den, </em>356 Or 767 (2015), where we concluded that the sender of a text message did not retain a privacy interest in the digital copy of the text message found on the recipient\u2019s phone, even if the sender \u201cdid not expect anyone other than [the recipient] to see the text message\u2014 or, at the least * * * did not expect law enforcement to see the message.\u201d So too here: Defendant did not retain a privacy interest in information that he provided to network users when he made files available for download, even if defendant expected that no other user would take notice of that information or find it particularly useful.</p>\n<p id=\"b74-4\">Defendant also asserts that Shareaza LE \u2014 what he calls \u201cadvanced computer technology\u201d \u2014 allowed for the kind of pervasive surveillance that the court found was a search in <em>Campbell. </em>He contends that Shareaza LE is just like the transmitter used in <em>Campbell </em>because it allowed officers to \u201ccontinuously monitor and scrutinize an immense amount of internet activity both day and night and then track down suspicious activity to a particular geographical location and, ultimately, a single computer.\u201d Again, we disagree.</p>\n<p id=\"b74-5\">Initially, we take issue with defendant\u2019s characterization of Shareaza LE. To say, as defendant does, that Shareaza LE allows for \u201ccontinuous, minute scrutiny of Internet activity\u201d misapprehends the constraints of Shareaza LE and the way that the police used it here. Because Shareaza LE connects to a peer-to-peer network, its search is limited to files that network users are sharing and to information associated with those files, like an IP address, that is available to other users. In that respect, it operates just like other software that accesses the network. Further, in this case, police used Shareaza LE to conduct targeted scans of shared network files for child pornography. <page-number citation-index=\"1\" label=\"55\">*55</page-number>We are not faced with continuous police monitoring of all of defendant\u2019s \u201cInternet activity.\u201d<footnotemark>14</footnotemark></p>\n<p id=\"b75-4\">There is no doubt that Shareaza LE creates important efficiencies for the officers in locating a network user sharing child pornography.<footnotemark>15</footnotemark> But the fact that Shareaza LE made police practice more efficient \u2014 by allowing for repetition and automation of the procedures an officer would go through without that kind of software \u2014 does not by itself establish that police conduct amounted to a search under Article I, section 9. The Supreme Court has \u201cnever suggested that use of <em>any </em>device or enhancement \u2014 no matter where that device or enhancement was used \u2014 would qualify\u201d as a \u201cconstitutionally significant \u2018search.\u2019\u201d <em>State v. Smith, </em>327 Or 366, 371, 963 P2d 642 (1998) (emphasis in original); <em>Wacker, </em>317 Or at 426 n 12 <em>(Campbell </em>did not establish \u201ca <em>per se </em>rule against the warrantless use by police of any technologically enhanced observation regardless of the circumstances\u201d). And the fact that technology has created efficiencies or conveniences in police practice does not mean that police conduct a \u201csearch\u201d when they use it. <em>See Wacker, </em>317 Or at <page-number citation-index=\"1\" label=\"56\">*56</page-number>427 (concluding that use of light-enhancing starlight scope to aid in seeing activity in a car parked in public parking lot was not a search, even though it allowed police to conduct surveillance without detection 29 feet away from car); <em>State v. Ainsworth, </em>310 Or 613, 618, 801 P2d 749 (1990) (concluding that police use of helicopter to view the defendant\u2019s property from the air was not a search, and explaining that, \u201c[wjhether on foot, by motor vehicle, boat, tall building, promontory, air balloon, or aircraft \u2014 the manner is unimportant if the officers are at a location where they are lawfully entitled to be\u201d); <em>State v. Louis, </em>296 Or 57, 61, 672 P2d 708 (1983) (concluding that there was no search when police used a telephoto lens, which allowed for \u201cmodest enlargement,\u201d to photograph activities inside of home from other side of street, where activities could be seen from the street without a telephoto lens).</p>\n<p id=\"b76-4\">Rather, the controlling questions as to whether police conducted a search, as shown by cases like <em>Wacker </em>and <em>Campbell, </em>are whether police were able to obtain information that was materially different from information the defendant made available to others and whether the police conduct swept so broadly that it amounted to pervasive surveillance of the defendant\u2019s daily life. Here, the answer to both those questions is \u201cno.\u201d The information that police obtained using Shareaza LE \u2014 particularly the IP address\u2014 was the same information that was available to any other user of the network. The police obtained that information by zeroing in on shared files that contained child pornography, not by engaging in all-encompassing surveillance of defendant\u2019s online activity. Accordingly, we conclude that the police did not conduct a search under Article I, section 9, and the trial court did not err in denying defendant\u2019s motion to suppress.</p>\n<p id=\"b76-5\">Affirmed.</p>\n<footnote label=\"1\">\n<p id=\"b60-7\"> Article I, section 9, provides that \u201c[n]o law shall violate the right of the people to be secure in their persons, houses, papers, and effects, against unreasonable search, or seizure [.]\u201d</p>\n</footnote>\n<footnote label=\"2\">\n<p id=\"b61-7\"> A hash value has also been described as \u201ca kind of \u2018digital fingerprint.\u2019\u201d <em>U.S. v. Wellman, </em>663 F3d 224, 226 n 2 (4th Cir 2011) (noting that the district court found that files with the same hash value have a 99.99 percent probability of being identical). The upshot is that it is highly improbable that two files with the same hash value will have different content.</p>\n</footnote>\n<footnote label=\"3\">\n<p id=\"b62-6\"> Hash values also enable faster downloads for eMule users. Even if users give the same file a different file name, eMule can identify duplicate files by their hash values. As a result, when a user selects a file to download, eMule can create a new file for the user by copying pieces of it from various users on the network (a faster method than downloading the entire file from one other user). eMule then puts those pieces together and compares the hash value of the newly created file with the source files to ensure that the new file is complete.</p>\n</footnote>\n<footnote label=\"4\">\n<p id=\"b62-7\"><em> </em>One of the officers explained that \u201cthe IP addresses are assigned by the Internet Service Providers and they have communications equipment in various places. At the major hubs, those communication equipments also contain the latitude [and] longitude of the location where that equipment is. That\u2019s how [Shareaza LE] determines initially that that IP address may be in that jurisdiction.\u201d</p>\n</footnote>\n<footnote label=\"5\">\n<p id=\"b64-7\"> Caffee did not know the particular search terms Shareaza LE used to find those files, but one of the files contained the terms \u201clOYo\u201d and \u201cWebcam\u201d and the other contained the terms \u201cIncest\u201d and \u201c13yo\u201d and described a sex act.</p>\n</footnote>\n<footnote label=\"6\">\n<p id=\"b64-10\"> Several publicly available websites allow a person to input an IP address and find the city, state, and ISP associated with that IP address.</p>\n</footnote>\n<footnote label=\"7\">\n<p id=\"b65-8\"> ORS 163.684 provides, in part, that \u201c[a] person commits the crime of encouraging child sexual abuse in the first degree if the person *** [k]nowingly * ** * disseminates * * * a visual recording of sexually explicit conduct involving a child\u201d and \u201c[k]nows or is aware of and consciously disregards the fact that creation of the visual recording of sexually explicit conduct involved child abuse.\u201d</p>\n<p id=\"b65-11\">ORS 163.686 provides, in part, that \u201c[a] person commits the crime of encouraging child sexual abuse in the second degree if the person <em>*** </em>[k] nowingly possesses or controls * * * a visual recording of sexually explicit conduct involving a child for the purpose of arousing or satisfying the sexual desires of the person or another person\u201d and \u201c[k]nows or is aware of and consciously disregards the fact that creation of the visual recording of sexually explicit conduct involved child abuse.\u201d</p>\n</footnote>\n<footnote label=\"8\">\n<p id=\"b67-5\"> Defendant does not challenge the officers\u2019 use of a subpoena to his ISP to match his IP address with a customer name and physical address. <em>See State v. Delp, </em>218 Or App 17, 20, 26-27, 178 P3d 259, <em>rev den, </em>345 Or 317 (2008) (concluding that the defendant did not have a protected privacy interest in records independently maintained by his ISP, which contained \u201cthe name, address, telephone number, subscriber number, local and long distance telephone billing records, length of service, and types of services utilized\u201d for the defendant\u2019s account). And he does not challenge the lawfulness of the warrant to search the computers at that address.</p>\n</footnote>\n<footnote label=\"9\">\n<p id=\"b67-6\"> The state also argues that defendant failed to preserve the arguments he makes on appeal. We disagree. As detailed above, defendant argued in the trial court that the officers conducted a search, even if they accessed \u201cinformation * * * available to third parties,\u201d and he asserted that \u201cnon-human surveillance\u201d like Shareaza LE was so \u201cinvasive\u201d that it should be treated like other technology that courts had determined to be a \u201csearch,\u201d <em>e.g., </em>\u201cGPS tracking\u201d and \u201cthermal imaging of homes.\u201d In making those arguments, which track the arguments defendant makes on appeal, defendant provided the trial court with an opportunity to identity its alleged error with enough clarity to permit it to consider and correct the error immediately. <em>State v. Wyatt, </em>331 Or 335, 343, 15 P3d 22 (2000).</p>\n</footnote>\n<footnote label=\"10\">\n<p id=\"b68-5\"> Although the issue has not been considered under Article I, section 9, several federal courts of appeals have considered whether users of peer-to-peer computer networks have a reasonable expectation of privacy, under the Fourth Amendment to the United States Constitution, in files and associated information that they share on the network. Those courts have uniformly held that users do not. <em>See U.S. v. Borowy, </em>595 F3d 1045, 1048 (9th Cir 2010), <em>cert den, </em>562 US 1092, 131 S Ct 795 (2010) (concluding that, because the defendant \u201clacked a reasonable expectation of privacy in the shared files [on a peer-to-peer network], [an agent\u2019s] use of a keyword search to locate these files did not violate the Fourth Amendment\u201d and rejecting the argument \u201cthat the use of a \u2018forensic software program\u2019 that is unavailable to the general public to confirm that the files contained child pornography rendered [the agent\u2019s] conduct an unlawful Fourth Amendment search\u201d); <em>U.S. v. Ganoe, </em>538 F3d 1117, 1127 (9th Cir 2008) (\u201c[W]efail to see how [an objectively reasonable] expectation [of privacy] can survive [the defendant\u2019s] decision to install and use file-sharing software, thereby opening his computer to anyone else with the same freely available program.\u201d); <em>U.S. v. Stults, </em>575 F3d 834, 843 (8th Cir 2009) (\u201cWe hold that [the defendant] had no reasonable expectation of privacy in files that the FBI retrieved from his personal computer where [the defendant] admittedly installed and used [file-sharing software] to make his files accessible to others for file sharing.\u201d); <em>U.S. v. Perrine, </em>518 F3d 1196, 1205 (10th Cir 2008) (\u201c[A]s [the defendant) conceded, he had peer-to-peer software on his computer, which permitted anyone else on the internet to access at least certain folders in his computer. To the extent such access could expose his subscriber information to outsiders, that additionally vitiates any expectation of <page-number citation-index=\"1\" label=\"49\">*49</page-number>privacy he might have in his computer and its contents.\u201d); <em>U.S. v. Conner, </em>521 F App\u2019x 493, 498 (6th Cir 2013) (same). <em>See also, e.g., State v. Roberts, </em>2015 UT 24, \u00b6 28, 345 P3d 1226, 1236 (Utah 2015) (concluding that use of software not available to the public to access peer-to-peer network was not an unlawful search under the Fourth Amendment); <em>State v. Peppin, </em>No. 32058-8-III, WL 1592442 at *6 (Wash App Div 3, Apr 9, 2015) (concluding, under state constitutional provision, that \u201ca person\u2019s private affairs are not disturbed when law enforcement uses peer to peer software to view files that the person voluntarily shares with the public on his or her computer\u201d).</p>\n</footnote>\n<footnote label=\"11\">\n<p id=\"b71-5\"> The court in <em>Campbell </em>cited an earlier version of the LaFave treatise in support of the notion that monitoring a transmitter on a car could not be equated with visual tracking. <em>See Campbell, </em>306 Or at 172 (citing Wayne R. LaFave, 1 <em>Search and Seizure </em>\u00a7 2.7(d) (2d ed 1987)).</p>\n</footnote>\n<footnote label=\"12\">\n<p id=\"b71-6\"> The Supreme Court has focused on another aspect of the conduct in <em>Campbell </em>in distinguishing it from police conduct that the court concluded was not a search. In <em>State v. Smith, </em>327 Or 366, 373 n 5, 963 P2d 642 (1998), in concluding that dog sniffs in public places are not searches, the court noted that <em>Campbell </em>\u201cinvolved a clear form of invasion, a <em>trespass. </em>The tracking device at issue was attached without permission to the defendant\u2019s privately owned vehicle.\u201d (Emphasis in original.)</p>\n<p id=\"b71-7\">But the court went on to say that it was not holding that, \u201cto qualify as a search, the invasion always must be of the type that the law traditionally has labeled as a \u2018trespass\u2019 \u2014 an actual physical intrusion.\u201d <em>Id. </em>at 373. The court explained that, \u201cif Article I, section 9, is to have any meaning, it must be read in light of the ever-expanding capacity of individuals and the government to gather information by technological means. It must, in other words, speak to every possible form of invasion \u2014 physical, electronic, technological, and the like.\u201d <em>Id. </em>Thus, although we acknowledge that <em>Campbell </em>involved a trespass and this case does not, the absence of a trespass is not dispositive in this case, which involves the use of a computer program to access information on a peer-to-peer network.</p>\n</footnote>\n<footnote label=\"13\">\n<p id=\"b73-7\"> We note that, contrary to defendant\u2019s suggestion, the fact that police were engaged in a \u201cdetermined effort\u201d to find network users who were sharing child pornography cannot be equated with police efforts to create a situation that forced defendant to expose information to others \u2014 conduct that has been deemed a search. <em>See State v. </em>Nagel, 320 Or 24, 31, 880 P2d 451 (1994) (concluding that an officer conducted a \u201csearch\u201d under Article I, section 9, when he conducted a field sobriety test because, in doing so, \u201c[t]he officer created a situation that exposed information about defendant that was otherwise not observable by either the officer or by members of the general public\u201d).</p>\n</footnote>\n<footnote label=\"14\">\n<p id=\"b75-5\"> Defendant also warns that \u201cthe state is not limited in its use of Shareaza LE to finding child pornography; the state could, at any moment, tweak the software to find files expressing political dissent.\u201d But those are not the facts before us. On that point, we find helpful the Ninth Circuit\u2019s rejection of a similar argument under the Fourth Amendment:</p>\n<blockquote id=\"b75-6\">\u201cBecause we decide only the case in front of us, we reject [the defendant\u2019s] argument that our decision will allow unrestricted government access to all internet communications. We do not rule on whether, if confronted with different facts \u2014 for example, where the information was not already exposed to the public at large, where the hash-mark analysis might reveal more than whether a file is known child pornography, or where the government \u2018vacuumed\u2019 vast quantities of data indiscriminately \u2014 we might find a Fourth Amendment violation. Here we are presented only with the limited case of a targeted search of publicly exposed information for known items of contraband.\u201d</blockquote>\n<p id=\"b75-7\"><em>Borowy, </em>595 F3d at 1048 n 2.</p>\n</footnote>\n<footnote label=\"15\">\n<p id=\"b75-8\"> Instead of an officer manually entering separate search terms associated with child pornography into standard peer-to-peer software, as a network user who wanted to find child pornography would do, Shareaza LE searches the network for several of those terms all at once. The software then filters those search results to identify files (1) with hash values known to be child pornography and (2) with IP addresses thought to be within Lane County. That filtering means that officers do not have to go through \u201cthousands and thousands\u201d of files, one-by-one, to identify files with a hash value predetermined to be child pornography, and they do not have to search \u201cthousands and thousands of different IP addresses\u201d to find a file with an IP address in Lane County.</p>\n</footnote>\n</opinion>\n</casebody>\n",
    "status": "ok"
  }
}